{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практическое задание\n",
    "## Метод обратного распространения ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### О задании\n",
    "\n",
    "В этом задание вы:\n",
    "* познакомитесь с методом обратного распространения ошибки \n",
    "* реализуете прямой проход и обратный проход в нейросети\n",
    "* реальзуете стохастический градиентный спуск с моментов\n",
    "* обучите нейросеть для классификации рукописных цифр"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 1. Прямой и обратный проход нейросети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Теоретическая часть\n",
    "\n",
    "<p>\n",
    "Метод обратного распространения ошибки — это метод обучения многослойной нейрононной сети, который впервые был открыт двумя независимыми группами исследователей в 1974 г. Этот метод определяет алгоритм эффективного вычисления градиентов параметров нейронной сети, что позволяется применить метод градиентного спуска в задачи минимизации функционала ошибки. \n",
    "</p>\n",
    "\n",
    "Давайте рассморим M-слойную полносвязную нейронную сеть.\n",
    "\n",
    "<img src=\"network.png\" width=\"800\">\n",
    "\n",
    "На рисунке верхний индекс всегда используется для обозначения номера слоя нейросети. Рассмотрим некоторый n-ый слой, который назовем текущим. Данный слой на вход принимает\n",
    "$N^{(n-1)}$, \n",
    "признаков \n",
    "$y^{(n - 1)}_i$, $i=\\overline{1\\mathinner {\\ldotp \\ldotp}N^{(n-1)}}$, \n",
    "которые являются значения выходов нейронов предыдущего слоя, и \n",
    "$y^{(n-1)}_0=1$\n",
    "(смещение или bias нейрона — константа, которая рассматривается как вход нейрона для упрощения записи дальнейших вычислений). Вес нейрона, связывающий $i$'ый нейрон предыдущего слоя с $j$'ым нейроном текущего, обозначен $w^{(n)}_{ij}$. \n",
    "За \n",
    "$z_j^{(n)}=\\sum_{i=0}^{N^{(n-1)}}{w_{ij}^{(n)}y_i^{(n-1)}}$, \n",
    "обозначена линейная комбинация входов и весов.\n",
    "$\\sigma^{(n)}_j$ \n",
    "— функция активации j'ого нейрона(так как функции активации нейронов в общем случае могут быть различны), а \n",
    "$y_j^{(n)} = \\sigma_j^{(n)}(z_j^{(n)}) = \\sigma_j^{(n)}(\\sum_{i=0}^{N^{(n-1)}}{w_{ij}^{(n)}y_i^{(n-1)}}) $ \n",
    "— значение функции активации или выход j'ого нейрона. \n",
    "\n",
    "<img src=\"layer.png\" width=\"800\">\n",
    "\n",
    "Резюмируем обозначения:\n",
    "* $M$ - колличество слоев\n",
    "* $N^{(n)}$ - колличество нейронов в $n$-ом слое\n",
    "* $\\{ w_{ij}^{(n)}\\}$ - веса нейронов $n$-ого слоя\n",
    "* $z_j^{(n)} = \\sum_{i=0}^{N^{(n - 1)}}{w_{ij}^{(n)}y_i^{(n-1)}}$\n",
    "* $\\sigma_j^{(n)}$ - функция активации $j$-ого нейрона $n$-ого слоя\n",
    "* $y_j^{(n)} = \\sigma_j^{(n)}(z_j^{(n)})$ - выход $j$-ого нейрона $n$-ого слоя \n",
    "\n",
    "За $E(\\boldsymbol{\\widehat{y}}, \\boldsymbol{y})$  обозначим некоторую диффенцируюмую функцию ошибки. Здесь  <br/>\n",
    "$\\boldsymbol{\\widehat{y}} = (y_1, ..., y_{N^{(M)}})$ - значение целевой переменной,  \n",
    "$\\boldsymbol{y} = (y_1^{(M)}, ..., y_{N^{(M)}}^{(M)}))$ - выход нейросети. \n",
    "\n",
    "Давайте попробуем оценить сложность вычисление частной производной функции ошибки $E$. Предположим, что сложность вычисления частной производной функции в точке приблизительно равна сложности вычисления самой функции в точке. Пусть нейросеть имеет M полносвязных слоем по N нейронов в каждом слое. Тогда:\n",
    "* $O(N)$ - cложность вычисления одного выхода одного слоя (перемножение N весов на N входов)\n",
    "* $O(N^2)$ - cложность вычисления всех выходов одного слоя\n",
    "* $O(M * N^2)$ - cложность вычисления функции ошибки (последовательно вычисляем выходы M слоев)\n",
    "* $O(M^2 * N^4)$ - cложность частных производных функции ошибки по всем весам (всего  $O(M * N^2)$ весов)\n",
    "\n",
    "Получается для нейросети, состоящей из одного слоя с 1000 нейронами, сложность вычисления градиента должна быть равна $O(10^{12})$. А это уже невероятно много.\n",
    "\n",
    "Идея метода эффективного расчета градиентов заключается в том, чтобы при прямом проходе нейросети сохранить некоторые вычисленные значения, которые потом позволят быстро находить градиент."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вычисление градиента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Будем вычислять частные производные функции ошибки от последних слоев в первым.\n",
    "Помимо частных производных \n",
    "$$\\frac{\\partial}{\\partial w_{ij}^{(n)}} E$$ \n",
    "будем вычислять значения производных \n",
    "$$\\frac{\\mathrm{\\partial}}{\\partial y_i^{(n)}} E \\quad \\mathrm{и} \\quad \\frac{\\mathrm{\\partial}}{\\partial z_i^{(n)}} E$$ вычисление которых является одним из ключевых моментов в алгоритме обратном распространения ошибки. \n",
    "\n",
    "Полезно посмотреть как аналитически выглядит вычисления выхода нейросети \n",
    "$\\boldsymbol{\\widehat{y}}=(y_1^{(M)}, ..., y_{N^{(M)}}^{(M)})$.:\n",
    "\n",
    "$$ \\widehat{y_j}=y_j^{(M)}=\\sigma_j^{(M)}(\\sum_{i=0}^{N^{(M-1)}}{w_{ij}^{(M)}\\sigma_i^{(M-1)}(\\sum_{k=0}^{N^{(M-2)}}{w_{ki}^{(M-1)}\\sigma_k^{(M-2)}(...)})})$$\n",
    "\n",
    "В случае однослойной нейросети, получим: \n",
    "\n",
    "$$ \\widehat{y_j}=\\sigma_j^{(1)}(\\sum_{i=0}^{N^{(0)}}{w_{ij}^{(1)}x_j}),$$\n",
    "\n",
    "двухслойной - \n",
    "\n",
    "$$ \\widehat{y_j}=\\sigma_j^{(2)}(\\sum_{i=0}^{N^{(1)}}{w_{ij}^{(2)}\\sigma_i^{(1)}(\\sum_{k=0}^{N^{(0)}}{w_{ki}^{(1)}x_k})}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вычисление градиента начнем с выходного слоя.** \n",
    "\n",
    "Вспомним как вычисляется выход:\n",
    "\n",
    "$$ y_j^{(M)}=\\sigma_j^{(M)}(z_j^{(M)})$$\n",
    "$$z_j^{(M)} = \\sum_{i=0}^{N^{(M-1)}}{w_{ij}^{(M)}y_i^{(M-1)}}$$\n",
    "\n",
    "Будем последовательно вычислять:\n",
    "\n",
    "1. $\\boldsymbol{\\frac{\\partial E}{\\partial y_j^{(M)}}}.$\n",
    "Так как функция E нам известна, то мы можем вычислить частные производные этой функции по переменным \n",
    "$y_1^{(M)}, ..., y_{N^{(M)}}^{(M)}. $ \n",
    "Например, если\n",
    "$$E(\\boldsymbol{\\widehat{y}},  \\boldsymbol{y}^{(M)}) = \\frac{1}{2} \\| \\boldsymbol{\\widehat{y}} - \\boldsymbol{y}^{(M)} \\|_2^2 = \\frac{1}{2} \\sum_{j=1}^{N^{(M)}}{( \\widehat{y_j} - y_j^{(M)}) ^ 2},$$ \n",
    "то\n",
    "$$\\frac{\\partial E}{\\partial y_j^{(M)}} = y_j^{(M)} - \\widehat{y_j}$$\n",
    "Заметим, что в этом случае частная производная $E$ по $y_j^{(M)}$ равна ошибки на объекте $x_i$.\n",
    "\n",
    "2. $\\boldsymbol{\\frac{\\mathrm{\\partial E}}{\\partial z_j^{(M)}}}.$ \n",
    "Функция ошибки \n",
    "$E = E(y_1^{(M)}, ..., y_{N^{(M)}}^{(M)}) = E(y_1^{(M)}(z_1^{(M)}), ..., y_{N^{(M)}}^{(M)}(z_{N^{(M)}}^{(M)}))$.\n",
    "Вычислим \n",
    "$\\frac{\\mathrm{\\partial E}}{\\partial z_j^{(M)}}$ \n",
    "применив правило вычисление производной сложной функции \n",
    "$$\\frac{\\mathrm{\\partial}}{\\partial z_j^{(M)}} E = \\frac{\\partial E}{\\partial y_j^{(M)}} \\frac{\\partial y_j^{(M)}}{\\partial z_j^{(M)}} =  \\frac{\\partial E}{\\partial y_j^{(M)}} (\\sigma^{(M)}_j)' $$\n",
    "Важно, что $(\\sigma^{(M)}_j)'$ берется в точке \n",
    "$$z_j^{(M)}= \\sum_{i=0}^{N^{(M-1)}}{w_{ij}^{(M)}\\sigma_i^{(M-1)}(\\sum_{k=0}^{N^{(M-2)}}{w_{ki}^{(M-1)}\\sigma_k^{(M-2)}(...)})}.$$ \n",
    "Заметим что при прямом проходе, мы  вычисляем значение $z_j^{(M)}$, теперь дополнительно при прямом проходе будет сохранять это значение. Тогда вычисление \n",
    "$\\frac{\\mathrm{\\partial}}{\\partial z_i^{(M)}} E$ \n",
    "представляет собой вычисление значение  $(\\sigma^{(M)}_j)'$ в уже известной точке и перемножение двух чисел.\n",
    "\n",
    "3. $\\boldsymbol{\\frac{\\partial E}{\\partial w_{ij}^{(M)}}}.$ \n",
    "Функция ошибки \n",
    "$E = E(z_1^{(M)}, z_2^{(M)}, ..., z_{N^{(M)}}^{(M)})$. \n",
    "Вспомним, что \n",
    "$z_j^{(M)} = \\sum_{i=0}^{N^{(M-1)}}{w_{ij}^{(M)}y_i^{(M-1)}}$. \n",
    "Вес $w_{ij}^{(M)}$ входит только в одну сумму $z_j^{(M)}$. Тогда:\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial w_{ij}^{(M)}}= \\frac{\\partial E}{\\partial z_j^{(M)}} \\frac{\\partial z_j^{(M)}}{\\partial w_{ij}^{(M)}} =   \\frac{\\partial E}{\\partial z_j^{(M)}} \\frac{\\partial(\\sum_{k=0}^{N^{(M - 1)}}{w_{kj}^{(M)}y_k^{(M - 1)}}) }{\\partial w_{ij}^{(M)}} = \\frac{\\partial E}{\\partial z_j^{(M)}} y_i^{(M - 1)} $$\n",
    "\n",
    "Таким образом, мы  за 3 шага вычислили $\\frac{\\partial}{\\partial w_{ij}^{(n)}} E$ для последнего выходного слоя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вычисление градиента произвольного внутренного слоя**\n",
    "\n",
    "Рассмотрим произвольный внутренний слой n. Вспомним что выходы этого слоя $y_i^{(n)}$ связаны с $z_j^{(n + 1)}$ следующего слоя соотношением:\n",
    "$$z_j^{(n + 1)}=\\sum_{i=0}^{N_{n}}{w_{ij}^{(n + 1)}y_i^{(n)}}, \\quad  j= \\overline{1\\mathinner {\\ldotp \\ldotp}N^{(n+1)}}$$\n",
    "Можно сказать, что \n",
    "$E = E(z_1^{(n + 1)}, z_2^{(n + 1)},..., z_{N^{(n+1)}}^{(n + 1)})$. \n",
    "А производные \n",
    "$\\frac{\\partial E}{\\partial z_{j}^{(n + 1)}}$ \n",
    "были посчитаны на предыдущем шаге.\n",
    "\n",
    "Тогда для \n",
    "$\\boldsymbol{\\frac{\\partial E}{\\partial y_i^{(n)}}}$ \n",
    "$$\\frac{\\partial E}{\\partial y_i^{(n)}} = \\sum_{j=1}^{N^{(n+1)}}{\\frac{\\partial E}{\\partial z_{j}^{(n + 1)}}} \\frac{\\partial z_{j}^{(n + 1)}}{\\partial y_{i}^{(n)}} = \\sum_{j=1}^{N^{(n+1)}}{\\frac{\\partial E}{\\partial z_{j}^{(n + 1)}}} \\frac{\\partial (\\sum_{k=0}^{N_{n}}{w_{kj}^{(n + 1)}y_k^{(n)}})}{\\partial y_{i}^{(n)}} = \\sum_{j=1}^{N^{(n+1)}}{\\frac{\\partial E}{\\partial z_{j}^{(n + 1)}}} w_{ij}^{(n + 1)} $$\n",
    "\n",
    "Эту величину, по аналогии с последним слоем будем называть ошибкой сети на скрытом слое. Заметим, что \n",
    "$$\\frac{\\partial E}{\\partial y_i^{(n)}} = \\sum_{j=1}^{N^{(n+1)}}{\\frac{\\partial E}{\\partial z_{j}^{(n + 1)}}} w_{ij}^{(n + 1)} =  \\sum_{j=1}^{N^{(n+1)}}{\\frac{\\partial E}{\\partial y_{j}^{(n + 1)}}}(\\sigma^{(n + 1)}_j)'  w_{ij}^{(n + 1)}.$$\n",
    "Таким образом, мы вычисляем ошибку текущего слоя через ошибку предыдущего, распространяя ее \"задом наперед\". Отсюда и название алгоритма — обратное распространение ошибок.\n",
    "\n",
    "Вычисление\n",
    "$\\boldsymbol{\\frac{\\mathrm{\\partial E}}{\\partial z_i^{(n)}}}$ и $\\boldsymbol{\\frac{\\partial E}{\\partial w_{ij}^{(n)}}}$ выполняется абсолютно аналогично последнему слою.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, мы умеем последовательно вычислять частные производные по всем весам от последнего слоя к нейросети к первому. Заметим что все произодные можно быстро вычислять матрично."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практическая часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части вам предстоит научиться:\n",
    "* вычислять производные среднеквадратичной функции ошибки и категориальной кросс энтропии\n",
    "* выполнять прямой и обратный проход неросети, состоящей из полносвязных слоей и функции антивации ReLu и Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1.** Вычисление производных функций ошибок\n",
    "\n",
    "Вам дан интерфейс класса `Loss`, вам нужно реализовать вычисление значение функции и ее градиента для среднеквадратичной ошибки $MSE$, а также для категориальной кросс-энтропии $H$. \n",
    "\n",
    "Пусть $\\widehat{y_i}$ - истинное значение функции, $y_i$ - предсказанное, тогда:\n",
    "$$MSE(\\boldsymbol{\\widehat{y}}, \\boldsymbol{y})=\\frac{1}{d}\\sum_{i=1}^{d}{( \\widehat{y_i} - y_i)^2}$$\n",
    "$$H(\\boldsymbol{\\widehat{y}}, \\boldsymbol{y})=-\\frac{1}{d}\\sum_{i=1}^{d}{\\widehat{y_i}\\log({y_i})}$$\n",
    "\n",
    "Для численной устойчивости вам предлагается также реализовать градиент связки `softax + crossentropy`(в функции `gradient_with_sofmax`). Преобразование $softmax$ над вектором $x=(x_1, ..., x_d)$ можно записать как \n",
    "$$y_i = \\frac{e^{x_i}}{\\sum_{j=0}^{d}{e^{x_j}}}$$\n",
    "Функция `gradient_with_sofmax` должна возвращать \n",
    "$(\\frac{\\partial E}{\\partial x_1}, ..., \\frac{\\partial E}{\\partial x_d})$\n",
    "(Вам необходимо выполнить аналитические преобразования над $\\frac{\\partial E}{\\partial x_i}$ так, чтобы аналичически он зависел только от $\\boldsymbol{\\widehat{y}}$ и $\\boldsymbol{y})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import base64\n",
    "import copy\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(abc.ABC):\n",
    "    @abc.abstractmethod\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        y_true: np.array(d), ground truth (correct) labels\n",
    "        y_pred: np.array(d), estimated target values\n",
    "        ---\n",
    "        output: loss\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def gradient(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        y_true: np.array(d), ground truth (correct) labels\n",
    "        y_pred: np.array(d), estimated target values\n",
    "        ---\n",
    "        output: np.array(d), gradient loss to y_pred\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanSquaredError(Loss):\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        d = y_true.shape[0]\n",
    "        ans = np.sum(( y_true - y_pred) ** 2 / d)\n",
    "        return ans\n",
    "\n",
    "    def gradient(self, y_true, y_pred):\n",
    "        d = y_true.shape[0]\n",
    "        ans = np.zeros(d)\n",
    "        for i in range(d):\n",
    "            ans[i] = -2 / d * (y_true[i] - y_pred[i])\n",
    "        return ans\n",
    "        \n",
    "\n",
    "class CategoricalCrossentropy(Loss):\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        d = y_true.shape[0]\n",
    "        ans = - np.sum(y_true * np.log(y_pred)) / d\n",
    "        return ans\n",
    "\n",
    "    def gradient(self, y_true, y_pred):\n",
    "        d = y_true.shape[0]\n",
    "        ans = np.zeros(d)\n",
    "        for i in range(d):\n",
    "            ans[i] =  - y_true[i] / y_pred[i]\n",
    "        return ans\n",
    "\n",
    "    def gradient_with_softmax(self, y_true, y_pred):\n",
    "        d = y_true.shape[0]\n",
    "        ans = np.zeros(d)\n",
    "        for i in range(d):\n",
    "            ans[i] = - y_true[i] * (1 - y_pred[i]) + (1 - y_true[i]) * y_pred[i]\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедитесь в правильности работы ваших функций с помощью небольшого числа unit-тестов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR_MSG = \"Error in test {}.\\n\\ty_true:{},\\n\\ty_pred:{},\\n\\tactual output:{}\\n\\tdesired output:{}\"\n",
    "\n",
    "def decode_answer(base64_string, shape):\n",
    "    buf = base64.decodebytes(base64_string)\n",
    "    return np.frombuffer(buf, dtype=np.float).reshape(shape)\n",
    "\n",
    "def check_answers(actual_values, desired_values, msg=''):\n",
    "    for i, (actual_value, desired_value) in enumerate(zip(actual_values, desired_values)):\n",
    "        msg = ERROR_MSG.format(i, Y_TRUE[i], Y_PRED[i], actual_value, desired_value)\n",
    "        np.testing.assert_almost_equal(actual_value, desired_value, err_msg=msg, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "\n",
    "SHAPE = (10, 5)\n",
    "Y_TRUE = np.rint(np.random.random(size=SHAPE))\n",
    "Y_PRED = np.random.random(size=SHAPE)\n",
    "\n",
    "MSE_ERRORS = decode_answer(\n",
    "    b'I0+rUDZfsj+65BmGzuvTP+ITdyZtp9E/jovoXZbOxj+tM4rNGfjRP8WqZPINQ7o/qkWFqWJrvj/YygOu3+7iP2xXHf8FLtc/nh8u'\n",
    "    b'JeH90z8=', shape=SHAPE[0]\n",
    ")\n",
    "\n",
    "MSE_GRADIENTS = decode_answer(\n",
    "    b'bbbcKhRtpD9tOdGaZi27v2ZYmkJFG3s//n322ZiNyr8m6+LE9aWjP6AI7iZLdsk/C3BaoCJ51T/NU4CxsQalvyCAv50cwdI/Jnla'\n",
    "    b'YuW0uL+ge/FUpbTMP8oHwWfBI8g/078UJnJrrD+agsQdii7Xv/P1Wpvcppe/ALOZhal2qz/J0z1DWiXQPy69kl9AdMK/KyUC2VwB'\n",
    "    b'zb+TKsfV3+qvP61ZjQQ/I6y/861aiGl80T9aw6ZZnY2hP05TbFQuN8a/pf7fNLXD1b91mBtGF3LIP2BQLEj8766/QK1QkZqzrD8A'\n",
    "    b'Z3EKfd/APyILN4pDvMK/IkWU2OF8w7/dKXoh5znEP2Op3oXyxcC/bf/5e0B1s7+ti6ZZedDDP8APmQhD5Ms/m5mMtC1R2T9T4D8Z'\n",
    "    b'LzfZPy+LSRFEHtC/gzVVrZfSzD+G39szoJO5P2acoFCBSoO/d+LLLFDn1D+yZblH9XbYv5OyW97C+8Q/nCtIKLzV2L9dGTmp/Em1'\n",
    "    b'P7SuSAYBJtA//Z/XUtyLwb+9hvZzq4e5Pw==', shape=SHAPE\n",
    ")\n",
    "CROSS_ENTROPY_ERRORS = decode_answer(\n",
    "    b'Lk/El56cyj/WBoxO/q6zP0unis259t4/pUfrxKNr0D96LACShLzgPwpVpmwNtr8/yNI87LnRyz93hYk3LG3JP09lbzfFF+Q/stF9'\n",
    "    b'Vtkm6T8=', shape=(SHAPE[0])\n",
    ")\n",
    "CROSS_ENTROPY_GRADIENTS = decode_answer(\n",
    "    b'AAAAAAAAAICQTFUt2sf1vwAAAAAAAACAmWpZOGWeAMAAAAAAAAAAgAAAAAAAAACAAAAAAAAAAICCQnznotTxvwAAAAAAAACAXyHI'\n",
    "    b'8ogW9b8AAAAAAAAAgAAAAAAAAACAAAAAAAAAAID9kuL7NywlwN9kei0D+/C/AAAAAAAAAIAAAAAAAAAAgNm59BtSBPm/wPXRt3J0'\n",
    "    b'AsAAAAAAAAAAgDhJMLFijPK/AAAAAAAAAIAAAAAAAAAAgIi4e0BwQ/y/9c0zp6WyGsAAAAAAAAAAgHD+3KnZ2PK/AAAAAAAAAIAA'\n",
    "    b'AAAAAAAAgFqtaQ7QO/m/QoDlrBTV+b8AAAAAAAAAgAhQB8ahy/e/DnZxuenA878AAAAAAAAAgAAAAAAAAACAAAAAAAAAAIAAAAAA'\n",
    "    b'AAAAgHRxm/JtmQXAAAAAAAAAAIAAAAAAAAAAgKLsIAbIYvC/AAAAAAAAAIDiZmdoeIw2wAAAAAAAAACA5l+CC9q6QMAAAAAAAAAA'\n",
    "    b'gAAAAAAAAACAtRNb8pFX+L8AAAAAAAAAgA==', shape=SHAPE\n",
    ")\n",
    "CROSS_ENTRY_GRADIENTS_WITH_SOFTMAX = decode_answer(\n",
    "    b'COSTNVmIuT/kw8IgYPzQv0B3oEkL8ZA/vw46iH+Y4L/wpRs2c4+4P8iKqfDd098/DgxxSGvX6j/AaOAdXki6vyhgL8Vjcec/cBfx'\n",
    "    b'uh7izr9E7RZV5/DhP7xJscGxLN4/5PfMVyfDwT9BozWlLPrsv3CzMcKTkK2/4A+A8ykqwT+7SA3UsC7kP3psd3dQEde/O1ehB9og'\n",
    "    b'4r+cepzly/LDPwxY2GIHlsG/cFlx6oPb5T8wdBCwBPG1PyJoh+n5xNu/Tv4XgqI067+SfqIXnY7ePzyyG639VcO/SGzSmkDwwT/A'\n",
    "    b'wA1NXBfVP+rNxGxUa9e/ala5Thpc2L9UtNjpYEjZP7xTVidv99S/SH/4mpBSyL+YLhCwl8TYP9ipX+WpbuE/AsCvIXml7z9o2I/f'\n",
    "    b'+oTvP/vtmxXVJeS/ckFVzJ4D4j9o19JAiPjPP4DDyKQhHZi/Fdv+NyQh6j8ev6eZspTuvzif8pWzOto/gzZaMisL77+0X4fTe5zK'\n",
    "    b'P2Ha2keBL+Q//IeNZ9Pu1b9sKPRQlunPPw==', shape=SHAPE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_errors = [MeanSquaredError()(y_true, y_pred) for y_true, y_pred in zip(Y_TRUE, Y_PRED)]\n",
    "check_answers(MSE_ERRORS, mse_errors)\n",
    "\n",
    "mse_gradients = [MeanSquaredError().gradient(y_true, y_pred) for y_true, y_pred in zip(Y_TRUE, Y_PRED)]\n",
    "check_answers(MSE_GRADIENTS, mse_gradients)\n",
    "\n",
    "cross_entropy_errors = [CategoricalCrossentropy()(y_true, y_pred) for y_true, y_pred in zip(Y_TRUE, Y_PRED)]\n",
    "check_answers(CROSS_ENTROPY_ERRORS, cross_entropy_errors)\n",
    "\n",
    "cross_entropy_gradients = [CategoricalCrossentropy().gradient(y_true, y_pred) for y_true, y_pred in zip(Y_TRUE, Y_PRED)]\n",
    "check_answers(CROSS_ENTROPY_GRADIENTS, cross_entropy_gradients)\n",
    "\n",
    "cross_entropy_grad_softmax = [CategoricalCrossentropy().gradient_with_softmax(y_true, y_pred) for y_true, y_pred in zip(Y_TRUE, Y_PRED)]\n",
    "check_answers(CROSS_ENTRY_GRADIENTS_WITH_SOFTMAX, cross_entropy_grad_softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.** Выполнение прямого и обратного прохода нейросети\n",
    "\n",
    "В этой части задания вам будет необходимо реализовать forward и backward проходы для 3-х типов слоев:\n",
    "* `Linear`, выполняет линейную комбинацию входов с весами $y_j=\\sum_{i=0}^{N}{w_{ij}x_i}, j=\\overline{1 {\\ldotp \\ldotp}M}$\n",
    "* `ReLu`, нелинейная активация $y_j^{(n)}=\\max(x_j), j=\\overline{1{\\ldotp \\ldotp}M}$\n",
    "* `Softmax`, $y_j = \\frac{e^{x_j}}{\\sum_{i=0}^{d}{e^{x_i}}}, j=\\overline{1{\\ldotp \\ldotp}M}$\n",
    "\n",
    "Вам дан шаблон нейросетевой модели, которая умееет последовательно добавлять слои друг за другом. Сейчас вам стоит обратит внимание только на функции `__init__`, `add`, `forward` и `backward`. Пока при инициализации модели параметр `optimizer` оставляйте равным None. Также вам дан абстракный класс `Layer`, который предоставляет интерфейс одного слоя нейросети. Вам необходимо реализовать функции `_forward` и `_backward`. Все вычисления необходимо делать матрично.\n",
    "\n",
    "Замечание:\n",
    "    обратите внимание на функцию `_build` слоя `Linear`, веса соответвущие bias'ам добавляются последним столбцом.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, loss=None, optimizer=None):\n",
    "        self._layers = []\n",
    "        self._loss = loss\n",
    "        self._optimizer = optimizer\n",
    "        self._outputs = None\n",
    "\n",
    "    def add(self, layer):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if not self._layers:\n",
    "            layer.build(optimizer=self._optimizer)\n",
    "        else:\n",
    "            layer.build(self._layers[-1], optimizer=self._optimizer)\n",
    "        self._layers.append(layer)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = inputs\n",
    "        for layer in self._layers:\n",
    "            outputs = layer.forward(outputs)\n",
    "        self._outputs = outputs\n",
    "        return self._outputs\n",
    "\n",
    "    def backward(self, outputs, use_gradient_softmax_with_loss=False):\n",
    "        if self._loss is None:\n",
    "            raise ValueError(\"Loss is not defined\")\n",
    "\n",
    "        if use_gradient_softmax_with_loss:\n",
    "            grad_outputs = [self._loss.gradient_with_softmax(outputs[i], self._outputs[i])\n",
    "                               for i in range(outputs.shape[0])]\n",
    "            backward_layers = self._layers[:-1]\n",
    "        else:\n",
    "            grad_outputs = [self._loss.gradient(outputs[i], self._outputs[i])\n",
    "                               for i in range(outputs.shape[0])]\n",
    "            backward_layers = self._layers\n",
    "\n",
    "        grad_outputs = np.array(grad_outputs)\n",
    "        for layer in backward_layers[::-1]:\n",
    "            grad_outputs = layer.backward(grad_outputs)\n",
    "\n",
    "    def update_weights(self, x_batch, y_batch, use_gradient_softmax_with_loss=False):\n",
    "        if self._optimizer is None:\n",
    "            raise ValueError(\"Optimizer is not defined\")\n",
    "        self.forward(x_batch)\n",
    "        self.backward(y_batch, use_gradient_softmax_with_loss)\n",
    "        for layer in self._layers[::-1]:\n",
    "            layer.update_weights()\n",
    "\n",
    "    def fit(self, X, Y, batch_size, epochs, shuffle=True, X_val=None, Y_val=None, use_gradient_softmax_with_loss=False):\n",
    "        size = X.shape[0]\n",
    "        X_train, y_train = X[:], Y[:]\n",
    "\n",
    "        self.loss_train_history = []\n",
    "        self.loss_val_history = []\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            if shuffle:\n",
    "                p = np.random.permutation(size)\n",
    "                X_train, y_train = X[p], Y[p]\n",
    "            for step in range(size // batch_size):\n",
    "                ind_slice = slice(step * batch_size, (step + 1) * batch_size)\n",
    "                self.update_weights(X_train[ind_slice], y_train[ind_slice], use_gradient_softmax_with_loss)\n",
    "            train_loss = self.evaluate(X_train, y_train, batch_size)\n",
    "\n",
    "            if (X_val is not None) and (Y_val is not None):\n",
    "                val_loss = self.evaluate(X_val, Y_val, batch_size)\n",
    "                self.loss_val_history.append(val_loss)\n",
    "                self.loss_train_history.append(train_loss)\n",
    "                print(\"Epoch: {:d}, train loss: {:f}, val loss: {:f}\".format(epoch, train_loss, val_loss))\n",
    "            else:\n",
    "                self.loss_train_history.append(train_loss)\n",
    "                print(\"Epoch: {:d}, train loss: {:f}\".format(epoch, train_loss))\n",
    "\n",
    "    def evaluate(self, X, Y, batch_size, metrics=\"loses\"):\n",
    "        if self._loss is None:\n",
    "            raise ValueError(\"Loss is not defined\")\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            raise ValueError(\"X and Y must have equal size\")\n",
    "\n",
    "        Y_pred = np.empty(Y.shape)\n",
    "        size = X.shape[0]\n",
    "        for step in range(size // batch_size + 1):\n",
    "            ind_slice = slice(step * batch_size, (step + 1) * batch_size)\n",
    "            Y_pred[ind_slice] = self.forward(X[ind_slice])\n",
    "            \n",
    "        if (metrics == \"loses\"):\n",
    "            losses = [self._loss(Y[i], Y_pred[i]) for i in range(size)]\n",
    "            return sum(losses) / len(losses)\n",
    "        else:\n",
    "            summ = 0\n",
    "            count = 0\n",
    "            for i in range(size):\n",
    "                nom = 0\n",
    "                for j in range(10):\n",
    "                    if (Y_pred[i][j] > Y_pred[i][nom]):\n",
    "                        nom = j\n",
    "                if (Y[i][nom] == 1):\n",
    "                    summ += 1\n",
    "                count += 1\n",
    "            return summ / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeInitializer(object):\n",
    "    def __call__(self, shape):\n",
    "        n = shape[0]\n",
    "        return np.random.randn(*shape) * np.sqrt(2.0/n)\n",
    "\n",
    "\n",
    "class ZerosInitializer(object):\n",
    "    def __call__(self, shape):\n",
    "        return np.zeros(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(abc.ABC):\n",
    "    def __init__(self, input_dim=None):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = None\n",
    "        self.inputs = None\n",
    "        self.outputs = None\n",
    "\n",
    "        self.d_inputs = None\n",
    "        self.d_outputs = None\n",
    "        self._optimizer = None\n",
    "\n",
    "        self._is_build = False\n",
    "\n",
    "    def build(self, prev_layer=None, optimizer=None):\n",
    "        self._optimizer = copy.deepcopy(optimizer)\n",
    "        if prev_layer is not None:\n",
    "            self.input_dim = prev_layer.output_dim\n",
    "        elif self.input_dim is None:\n",
    "            raise ValueError('Input dimension is not determine.'\n",
    "                             'If this first layer, please, use param \"input_dim\"')\n",
    "        self._is_build = True\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if not self._is_build:\n",
    "            raise ValueError(\"Layer is not build\")\n",
    "        if inputs.shape[1:] != (self.input_dim,):\n",
    "            raise ValueError(\"Input shape is not correct\")\n",
    "        return self._forward(inputs)\n",
    "\n",
    "    def backward(self, grad_outputs):\n",
    "        if self.inputs is None:\n",
    "            raise ValueError(\"Forward pass is not performed\")\n",
    "        return self._backward(grad_outputs)\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def _forward(self, inputs):\n",
    "        \"\"\"\n",
    "        inputs: np.array((n, d)), input values, n - batch size, d - number input features\n",
    "        ---\n",
    "        output: np.array((n, c)), output values, n - batch size, c - number output features\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def _backward(self, grad_outputs):\n",
    "        \"\"\"\n",
    "        grad_outputs: np.array((n, c)), gradient by outputs,\n",
    "                      n - batch size, c - number output features of this layer\n",
    "        ---\n",
    "        output: np.array((n, d)), gradient by inputs,\n",
    "                n - batch size,  c - number input features of this layer\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def update_weights(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Layer):\n",
    "    def __init__(self, units, input_dim=None,\n",
    "                 weights_initializer=None, bias_initializer=None):\n",
    "        super().__init__(input_dim)\n",
    "        self.output_dim = units\n",
    "\n",
    "        self.weights = None\n",
    "        self.mean_d_weights = None # mean value gradient weights by batch\n",
    "\n",
    "        self._weights_initializer = weights_initializer if weights_initializer else HeInitializer()\n",
    "        self._bias_initializer = bias_initializer if bias_initializer else ZerosInitializer()\n",
    "\n",
    "    def build(self, prev_layer=None, optimizer=None):\n",
    "        super().build(prev_layer, optimizer)\n",
    "        weights = self._weights_initializer((self.input_dim, self.output_dim))\n",
    "        bias = self._bias_initializer((1, self.output_dim))\n",
    "        self.weights = np.vstack((weights, bias))\n",
    "\n",
    "    def _forward(self, inputs):\n",
    "        n = inputs.shape[0]\n",
    "        ans = np.zeros((n, self.output_dim))\n",
    "        self.inputs = inputs\n",
    "        for i in range(n):\n",
    "            inputs_arr = np.tile(inputs[i], (self.output_dim,1))\n",
    "            ans[i,:] = (inputs_arr.T * self.weights[:-1,:]).sum(axis=0) + self.weights[-1,:]\n",
    "        return ans\n",
    "\n",
    "    def _backward(self, grad_outputs):\n",
    "        n = grad_outputs.shape[0]\n",
    "        self.mean_d_weights = np.zeros(self.weights.shape)\n",
    "        ans = np.zeros((n, self.input_dim))\n",
    "        for i in range(n):\n",
    "            for j in range(self.input_dim):\n",
    "                ans[i, j] = np.sum(grad_outputs[i] * self.weights[j,:])\n",
    "        count = 0\n",
    "        for i in range(n):\n",
    "            grad_z = grad_outputs[i]\n",
    "            grad_y = np.hstack((self.inputs[i], np.array([1])))\n",
    "            grad_z_arr = np.tile(grad_z, (grad_y.shape[0], 1))\n",
    "            grad_y_arr = np.tile(grad_y, (grad_z.shape[0], 1)).T\n",
    "            Tmp = grad_z_arr * grad_y_arr\n",
    "            count += 1\n",
    "            self.mean_d_weights += Tmp\n",
    "        self.mean_d_weights /= count\n",
    "        return ans\n",
    "\n",
    "    def update_weights(self):\n",
    "        self.weights = self._optimizer.update_weights(self.weights, self.mean_d_weights)\n",
    "        pass\n",
    "\n",
    "\n",
    "class ReLU(Layer):\n",
    "    def __init__(self, input_dim=None):\n",
    "        super().__init__(input_dim)\n",
    "\n",
    "    def build(self, prev_layer=None, optimizer=None):\n",
    "        super().build(prev_layer, optimizer)\n",
    "        self.output_dim = self.input_dim\n",
    "\n",
    "    def _forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        ans = (inputs > 0) * inputs\n",
    "        return ans\n",
    "\n",
    "    def _backward(self, grad_outputs):\n",
    "        ans = (self.inputs > 0) * grad_outputs\n",
    "        return ans\n",
    "\n",
    "    def update_weights(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Softmax(Layer):\n",
    "    def __init__(self, input_dim=None):\n",
    "        super().__init__(input_dim)\n",
    "\n",
    "    def build(self, prev_layer=None, optimizer=None):\n",
    "        super().build(prev_layer, optimizer)\n",
    "        self.output_dim = self.input_dim\n",
    "\n",
    "    def _forward(self, inputs):\n",
    "        n = inputs.shape[0]\n",
    "        ans = np.zeros((n, self.output_dim))\n",
    "        self.inputs = inputs\n",
    "        ans = np.exp(inputs)\n",
    "        sum_arr = np.tile(ans.sum(axis=1), (inputs.shape[1], 1)).T\n",
    "        ans /= sum_arr\n",
    "        return ans\n",
    "\n",
    "    def _backward(self, grad_outputs):\n",
    "        n = self.inputs.shape[0]\n",
    "        m = self.inputs[0].shape[0]\n",
    "        ans = np.zeros(grad_outputs.shape)\n",
    "        sum_arr = np.exp(self.inputs).sum(axis=1)\n",
    "        for k in range(n):\n",
    "            einput = np.exp(self.inputs[k])\n",
    "            ans[k] = -np.dot(einput * grad_outputs[k], np.tile(einput, (m, 1)))\n",
    "            ans[k] += einput * grad_outputs[k] * sum_arr[k]\n",
    "            ans[k] /= sum_arr[k] ** 2\n",
    "        return ans\n",
    "\n",
    "    def update_weights(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедитесь в правильности реализации вами функций с помощью небольшого числа unit-тестов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_answer(base64_string, shape):\n",
    "    buf = base64.decodebytes(base64_string)\n",
    "    return np.frombuffer(buf, dtype=np.float).reshape(shape)\n",
    "\n",
    "np.random.seed(123456)\n",
    "\n",
    "INPUT_DIM, OUTPUT_DIM = 4, 6\n",
    "BATCH_SIZE = 3\n",
    "COUNT_TESTS = 10\n",
    "\n",
    "INPUTS = np.random.normal(size=(COUNT_TESTS, BATCH_SIZE, INPUT_DIM))\n",
    "WEIGHTS = np.random.normal(size=(COUNT_TESTS, INPUT_DIM + 1, OUTPUT_DIM))\n",
    "LINEAR_D_OUTPUTS = np.random.normal(size=(COUNT_TESTS, BATCH_SIZE, OUTPUT_DIM))\n",
    "RELU_D_OUTPUTS = np.random.normal(size=(COUNT_TESTS, BATCH_SIZE, INPUT_DIM))\n",
    "SOFTMAX_D_OUTPUTS = np.random.normal(size=(COUNT_TESTS, BATCH_SIZE, INPUT_DIM))\n",
    "\n",
    "LINEAR_OUTPUTS = decode_answer(\n",
    "    b'wGm3fs21079DBbbsam/fv0YsX4hX9/o/Nxh4K63n8T++UomsDXPrvxbi2hKA8gjAl03DtDo1AcB05j4D6Bvcv1d2xALzbwBADAx/'\n",
    "    b'H0G0AkD31QxMgaX0P+gv0xPBnfK//f64pm5VBUDLFwHUBV4EwAiYgNzWLA3Ax4deeVK9AsDYJpe26kwEQGVn2t7ZWwLA/HC9xMss'\n",
    "    b'9L+IeOKWVevZv5Rfd295DbI/WHvyPVAW979E6GKRpFPmP8x4zXNcUwTAqCRqOrLM8T/151+zeYr+vx6bEJiWGNC/mhc6p5SqAMCh'\n",
    "    b'SuMGWLDcv24FuPkfPeU//mbyah5d9r+ucwIVIU3oP81dEoOegQVAyKhCIITQDcAwTKAcRY4NQPjHLQNXwALAestiiX2EBkDemn7g'\n",
    "    b'j8DwvzBqu0YGnPw/wNLLm4gz8r8MoZpd8svwv/70sbu0xP2/4Z0Nh94+AMAow1b45oIKwMdHYH/MvwrA506PZHXj4z9aLm5Z2+3s'\n",
    "    b'P8Tk/paM3gZAqCclSm3M+z9pzl5fkHIYQBkKiIdTjRJAkWkBGd358D/IbqQCKN77v7JS+XYenvC/Bo9V1xLnEEAkelfNQC3kPwGY'\n",
    "    b'/nu93/8/sE1Qipm89L/QNoNnBFqkv0TCcC86m+I/tLP+xucZ0j8QA6VJV2HiPyc1Ru5nFgJA5efyWSarA0Cc5Fqc2qrNv2vZQdXk'\n",
    "    b'sQDALOJVE8sv/j/mrk0EYifjP+4ZCcQaJPc/V0d//SUe5b+gPNHw9VzSP/hOIius5gTANiVWAomHFcD7wcLEf3Dwv8EPRV+UIBlA'\n",
    "    b'KHyQtLH1+T9gr+67iXUGQHyz3s0wTNE/1vmK3JcAD8AxuOL3pTL4vwVlfP0a6xdAKk4O0RKRE8DzJk+ETJP1Pwml9+piFgrAsEbz'\n",
    "    b'ANbAC8AYXacpBbXOvxRlJ9bEeOo/yaILuC6LCsDiNBbTRO7Vv6RKEPT8Avu/2uPPVplQ0j+jPgFnam6xvyGX5u0PhPC/X2dnCYQR'\n",
    "    b'EsCgGkfU3kHgvxQ0Am3FNss/V6Y63wHpC8A7tmYislPcPxQ+0M8ZYhFAQIPzNBpF+r9Yv2NY7SoQwOyBsYbZNvI/qLCJjvaL/D9S'\n",
    "    b'O4Mv3CS1vyftMo9OnAvAhP5pHLgYFcAg3GyiFC/pP+R7Q28JJ9C/p96cZCbV8z8pY0LfW6vpv2tGIwTKyxFAmtN1h/cK5T/uR0Ff'\n",
    "    b'LpEEwIOjB57uAfw/iH3ZhwYzB0BipUya/4/pPyz9FjDi5hdARbRzUdzv7j+YYMxaOSILQHANapLprda/IlSg8sQ28D8xDBK2gxnm'\n",
    "    b'P5CW0s+gnbY/gDZeg85Czj9SuLWI8vwLwHZfxhQpCN2/ir6FkxvEEsCShlKitBX2v9rq22/+hvO/QiehO1HX0j/eww3Ft83nP6Vs'\n",
    "    b'dgmGtAZAlP8lO1X99D9QydHZ4nXvPwZiWA6Ssea/TJJIWptA9r/uWjqs06v+v9An3PViyO6/KrQViu7RCcA+Kh7hTMu/v2zoa2ZW'\n",
    "    b'jBXAHrrgqgSM/j8gvM4nNqT3v4xtpLcZYRdAfoxz/N45DsA80sT+DY3yP15FUTkjIPo/oLiF9fzN9T94wKgxQHy9P4DTllkw19O/'\n",
    "    b'MtKPpb+g0b9yPM4rr97iv6xle4TvzP2/0gweWXoCDEBU3w4wKx30P9hmJE5kSAbAJkOcNM34G0BNIxfvXRcTwKb78y1erPe/lJ/Y'\n",
    "    b'redW+L9e47yfGZn1P0ZEwUoRiQHAzIFyAjDGAUC8bw0idVf2vyJwOBRMmAFAL+NuZOhDC8D+5VZNXyoJQLCicm3ysPW/SB7Coj/M'\n",
    "    b'2T8sjM1DuEzrv+rph7ycMhFAPyaGKEi3E8A02vtrHaXqP6L4cDNZe+y/c/Ys2fxu5r8nf4qpwmcSQIi0Q9ysMPI/Fh10yO1sDUAG'\n",
    "    b'6RLr7PUDwG5OmwH+59o/',\n",
    "    shape=(COUNT_TESTS, BATCH_SIZE, OUTPUT_DIM)\n",
    ")\n",
    "LINEAR_D_INPUTS = decode_answer(\n",
    "    b'P2edUgWR+r/bzKvlk3bjP9szpDHiifi/LYE0nMt2779h0J1t7RAMwPm13hRgIvo//0PlFKvn078mY9lXhU7dvzHH2LklFRVAj3BH'\n",
    "    b'TpX7AUDEabx1uEIHwBJTpAf2u9k/2UASQZeD0b8ZiUrHtnD5PzUUC+5tqgHAhKA4PIjR8L98KhExIHv1vyfDZ2OKQPy/z8zIh0tu'\n",
    "    b'DsBRGTYBOEEJwLQRGDDCDRHAq91D5VKlIMD95gLQO6QaQI8ES0rhliJAfZgckVxv9T9G/aTxuLrFvwv4niwXcfg//CNiqtSf67+s'\n",
    "    b'xePaogPqP/8f44x7EwzATjSTlQa21z+fmux6IjwPQGMvrv8zShHAbJQRvmQGAcBPLH4HSQ72vxmsITDMDiNAlDrNEjW99D9csOJ6'\n",
    "    b't7T+P93HoYdoKfM/7k3sVZ6J9r/6iK3y2S7ZP/l1IQvc7QTAFTesB+Nb9L9kIG01nPj/v++DG90/aeA/bOFczA0HAMBKeBXJECcV'\n",
    "    b'QEJNe+3vpBvAnwLL8efe4D+bRDTq7ezfv21YsH6B+vM/L6CZoBR21D8hMDDp4yT8v6XULQufIPY/s7GQkbha+b8exktRol0VQAQM'\n",
    "    b'qBQ/ZeI/qeq5APRYjb+lhC8HfqQCwBQiLbLre/u/0xv/24Gi3r801ygQjJv1P2KwMlh6H/u/NUi9uPw/8z8t3X2eBLfzPxLxpw5f'\n",
    "    b'N+c/RyP/A/ah4j+EobO9K38RwPXhyZcCAQFAVmb/UNjVB8Cd/+qN1o0OwK8yktnHcAjALgt4XYrD+L93CbzwJHv7v/0mhN5VO+u/'\n",
    "    b'SzTIYQ0H4j8Mc01xk1QPQFeOI+NWUQXAsP1mWBWl4r9uhE6QjNMEwGcPimeXce6/yI1g6owq8j9edpTiY4H9v1VBS0rUMwHA3wpn'\n",
    "    b'JKiM+b+gmZUgyMLWP4WXYJ9+lw9A5fhvmrbi5T8tCSJlLwIeQJrtuTutefk/4bkQwFPWEsAgAwRhO+QLwHwagU32TAHA4SMOiYKI'\n",
    "    b'7L+6FngpMMgBQDjYeTf1/Ok/4+2b7LP1+b+gXzZ1qKgMQBElUKRe0tW/cOWiD+H+9T/QarjGuP/8PzmlXoBeww3AIHsffOvw5b9P'\n",
    "    b'4Y9kZCcKwFfPnIHSDwtAwb567vp4wz9AImNVabrQv1ilXYAKTua/yRTFuDpc0b8Rxpcdo6QLQFhZ/XLpVQfAzrFbKSnx8b/4OfW8'\n",
    "    b'ovQFwL295MDX1Oo/pTQXX+ZsAMAKax04xwvwv8jcCidyEgLAYlrJn2I4CUBWSMjMKagOwAkewz9Jnum/',\n",
    "    shape=(COUNT_TESTS,  BATCH_SIZE, INPUT_DIM)\n",
    ")\n",
    "LINEAR_MEAD_D_WEIGHTS = decode_answer(\n",
    "    b'arfqHIAf479QsLlR0m7Wv+jN7ldX6+y/BpChF3zO4r+iO2bPKy/kv/2bdU6oisS/DiFD39Ma1L99QrcdZLrNv0KzC2HEb/K/n35H'\n",
    "    b'WJ2J3b83YGFa7N7kPyNAC1DDoqS/+CC4vvv+zj9Das+5yKinv5tyGRSeGMI/OWWympzx07+Ftb6M3CfgPxMqUKMHYOk/Nb1MLbVm'\n",
    "    b'6D+MCqeZckvXP0VSDrTOPvM/QNo7F1dP4D9TTSLALTPmPxnZ6L6n8uE/3Eoyzo780r+fv7SODo61v9CWDJI137k/4DEvqKkblb+7'\n",
    "    b'URIg42vxv2kD6okB3NS/1AllJjKQ6z98C8dIGr95P81bRcd3OMa/BFQe+lkr4L+/6OnoQdOjPzF9zjIkkK4/FIdNlRa5yb8VCkvn'\n",
    "    b'xhHBv9Uf8azEtL8/ynoNTAMDoj9/VXgneSTDv6jl+qMRrsq/d2DyQa0S+j8ZYBX9Kd3Wv3PPiSI6+bC/hABDe4iF67+1RrhSNQnX'\n",
    "    b'v4wdMNwj5tW/7ADbBBAx47+VPRR0msPVPzEC2dIDlrO/S3U26I2L6T9w8uvHkfbTP9VwiTbq7+A/J46sCQnu8L8r2SLRrSZ8v26W'\n",
    "    b'ATJ6fMM/i2TxxobCsL8doERHZ/aiP8NirrEgmtC/Y/YOGLrk5b+tous4Fn/Tv4hZTNPnst6/QTwB4nVetb+/ehcpxL3HP/EEdNKq'\n",
    "    b'lKs/aCawyDkg2T9VvYpYnG6nvw9Oou01DM0/B26MkVIuwj9VcuoOy1/wv+aK6ClOqdS/GZdYPeuC7L9PJw3O2YPnv0yt1binSPW/'\n",
    "    b'AvgQvByj47/p2QORQK/bP5kxgHJOquq/Vdq8oh/F6j+j8vUqhWvaPzIRwuMfwOA/DCCeqHZohj99+R1SI2S/PwoU1KtTfLC/YGIZ'\n",
    "    b'rKge77/DRA+HjlO3v9P2TkRFW9O/GBq7h6bRqD9b951ij0jtP0vtuEvb9uc/EXFrNq2E0D+D5QuRJ7LaP4OWI2iSLtK/8VhmW9yj'\n",
    "    b'6z+dFaRn5u7YP/PEW9U1tdy/bPa3t4Bz078x2BNPJKPRv4tp66+QyMc/SVuo3FgN1L8J3jF1nFGaP3TnWOkLt+c/2p2TlN2b5L8o'\n",
    "    b'wi8r7ofUvxs0iRHaQuQ/91Qlr9zt5L8MdWywPQGvv7Qm8jXTfec/Yz3Vr3y41r9ZP+2CQdbEv8rYDpBmOqA/l1NCINeT0z8JH8QE'\n",
    "    b'xXXgP76jPbRvg/M/oSJ5KdU81D8VQK3fVCyeP2vMKOhM56U/BZzrQA065L+Y7tDchoDmv0octzYo2PK/09Tl2se20L+VR9p6w6ng'\n",
    "    b'Py97+8+YdO8/GY2Ne+aDxT//8cj2z4qnvyWuZEad4fU//Jk/MSbXxL+8SsKLs3LgPxx0RhYjCu8/rOc0IsdnuT9Il9BhEieov3dg'\n",
    "    b'rP6KYPM/32QVYgu+0z+tURTx01/evxOE+J83UOm/SOaIvyUquL98UvdfsyO1P3Djfkny2/a/b+oz3DbMwb/U+UYpwcjVP3wfVR7E'\n",
    "    b'0Hk/odno8Hwq4r9XLF9XhDrSv6mFfNKLPPU/8HTl7HDNqr8P80KavPfePzXrvspu5+k/cQNiV0l3tb+biTHuj2u2v/MKMn9aIPE/'\n",
    "    b'i4Sjw58d5z8JlSifqwagv3cTV0MnJsm/zwNNPCVt8z/4vZrAbNHVP+gMHM9KvNo/KaoVfEMGAcCPuG9bwtziv8QXBlKdu+4/QzGT'\n",
    "    b'GegB+b9lyoyc+1XoP+8L5L0RquO/ud2z2b/s8D8eEsYVvIjiP1vPVU+/Cey/vFGN6Z9Y5r9vdHeb1az1v9H53gnWF72/gAvQjsoI'\n",
    "    b'AMCPnUx6VQnnv+NlhZ7DnPE/NC7dg5i/5r/HnktUju3zP3f4u/xaCde//W+EBL/C8D9h+aILAbbgP0OyioqCqey/WWjYgB0R5r9z'\n",
    "    b'c30eDzz0vwTjxye+sbq/ShLZt0cwsz8ovJGv+SHkP4Vl9csAA7C/rpcmJq4Z5b+EfET8lCvHP26w3mw9f4S/M9Cb/myByr+XP+IA'\n",
    "    b'c4XevwmdPXKelpo/3aoZilJwzj/5E1EgvB7Avwkbzzl1q6u/G4Wj3MoP5T+FnN3skvfmP8XZHeUb/ZM/59vxTkuRwb8jL7TU7aTR'\n",
    "    b'P1XrcMOdsrk/aWPI3zX0tb+3s6jTXT3Yv9mqBKsh2K0/uJXE+4YR6b9MJvsDFPbLP/Gx8J+Vdte/mX7Xh41b3T/D+uSIDyTlv4DA'\n",
    "    b'qy2aRcQ/tdjMwp6p7j/ldmmKBnqhvxVipc8j1Y8/kY6ZUT/82j90Z6cf+vKfv/0jJMafAtg/t8+tW7Tbvj+454FNAAimv1kdWjA2'\n",
    "    b'XOi/CzZ2TdEo279o8RYchjq/P0OZtGmgxtO/JezwgRUfyL83blLkT2yhP/knW//60uo/1fEmQXrO5b/2+0nprcHRv3vLkB5zzt6/'\n",
    "    b'19DiGucd3T/M79EZ2qXmv63cP7s/kdU/MSsrLva51b+MhISLNzjdv7Kw9U8d0eC/geJJfPp72j/zlqT5CIXMv7fb8xOe1IO/bkbV'\n",
    "    b'wBEO0T8lJPnG377gv+o7CHnhleC/1Qhtj/ZJpT+IJwjf7srqPwG3ZFVGus+/H3VAagNd1L/AxlnIbfr2vzYGDaCWLtK/B5QBlpJZ'\n",
    "    b'9b/BhKXLoaXjv/x0heWipOi/Sem05AlN5b/fK/5MeT7ev/XH6nI1a9K/28QbyMIu4r+cuOK2SWXyvwSSD7LmPcm/4cdGYiw62r80'\n",
    "    b'ZFYQs/0DwKmgrBRly9a/4J3ru6g3BcAcQAUQu8b2v2C1VwG7Pue/7swLWfwq0z+rJCsbpIPNv0MB99PE9sY/P2TEcWzp4b/oRKlM'\n",
    "    b'/JXKv5+O0sNMe+I/qz3oRYwh6L94gghIDufvv8xcrZb619i/nABHslxf8L/bB/6O4I30v+t/YsOD0uC/bF58i6Iv3L8B+DE7Wsb3'\n",
    "    b'P1/XDYzjKOO/CvVrQwC/4b+zkB8mNBndP6N8te73c4w/LaByY+YuvD++sT3s1H7Qvzz04N5Lesu/YnFoVUVdkr85E4jMjraXvxGb'\n",
    "    b'kuucnJq/dUkB69gLtj9fm91p0qDVvzQrCT8+oNM/V7k2cw/vuz/PbjpBIAi3v8mUtCcw/dK/O6P/YvXzxD9yZgOdPh3iv34KQUqg'\n",
    "    b'adM/atEm4hTJxD9EZC3renrCv4JwkSmHAtO/X2JvdLjZ4j+RROs4lg38v30HXm6IBck/a3HT1JvmxT9tLRZWofnRv6x/rrVosvO/',\n",
    "    shape=(COUNT_TESTS, INPUT_DIM + 1, OUTPUT_DIM)\n",
    ")\n",
    "RELU_OUTPUTS = decode_answer(\n",
    "    b'YiyQmO8F3j8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACg2CiUz2TzPwAAAAAAAAAA5CtrTHaEvj8AAAAAAAAAAAAAAAAAAAAAAAAA'\n",
    "    b'AAAAAAAAAAAAAAAAADJCr78bJvE/WS8D2voW5z8AAAAAAAAAAAAAAAAAAAAAaQxgASdm0T8AAAAAAAAAADv4UNwHJeI/V/k5EMmt'\n",
    "    b'0T8AAAAAAAAAAAAAAAAAAAAAIy7b6g8YvT8AAAAAAAAAAKTzoe+yzOA/ISOwt7Dm2T81IbokKXfiPwAAAAAAAAAAAAAAAAAAAAAA'\n",
    "    b'AAAAAAAAAAAAAAAAAAAAAAAAAAAAAACSemmQTAnrPy1VcWBaNvE/AAAAAAAAAACF50HKCEz6PwAAAAAAAAAAwd68x2zZ1j8AAAAA'\n",
    "    b'AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD6952Oveto/vCtLVNO00T8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA'\n",
    "    b'AAAAAAAAAAAAXxHvVLep7D85r0oej8TpPwAAAAAAAAAAt63DYXGGBEDB+lOtbOb2P/bXRrHncfU/AAAAAAAAAAAAAAAAAAAAAJBN'\n",
    "    b'ZdUcS9o/pBgdwQ8L6j8av8TZeuXAPwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHkBh1wAFfI/AAAAAAAAAAAAAAAAAAAAAAaRztEK'\n",
    "    b'uvk/2udSvApj8D/gzG3RNDriPwujSd1sB+w/AAAAAAAAAACoQyp30y7vPwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgTDylweOE/'\n",
    "    b'AAAAAAAAAAAAAAAAAAAAAAzBuD87oug/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACEltIyyUPmP2Oqm8b53tU/iBCS'\n",
    "    b'chK27j8AAAAAAAAAAAAAAAAAAAAAtdJt8fMqwz8AAAAAAAAAAIi+ZPDzAeY/DW95bLqVxj/pR+S/0s/ZPwAAAAAAAAAAPraYpdBN'\n",
    "    b'0z8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAVSfL4M2f3PwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHGHHIgYB/U/9MSA1TkZ5j+m'\n",
    "    b'K3z4Rd3vP33JHTebLANAKp/kCql0jj8w2YC2AtwKQAAAAAAAAAAAAAAAAAAAAACmls8Rbq3sPwAAAAAAAAAAAAAAAAAAAAAAAAAA'\n",
    "    b'AAAAACSn9qtmWNg/oXMhsVm4tT9KDGAkRqzbPwY2K17MUfg/AAAAAAAAAABnNImjpzTjP5ENrHP7jNE/',\n",
    "    shape=(COUNT_TESTS, BATCH_SIZE, INPUT_DIM)\n",
    ")\n",
    "RELU_D_INPUTS = decode_answer(\n",
    "    b'A2itoRO18L8AAAAAAAAAgAAAAAAAAACAAAAAAAAAAIAHh/vZZPO/PwAAAAAAAACAWRIg0o5y1b8AAAAAAAAAgAAAAAAAAACAAAAA'\n",
    "    b'AAAAAAAAAAAAAAAAABE1RhH4o8o/KgQl1O5e5L8AAAAAAAAAAAAAAAAAAACAuuBfgdfy3T8AAAAAAAAAAOFo1PooyfQ/kqsXtUZd'\n",
    "    b'7z8AAAAAAAAAgAAAAAAAAACA0Ev2eU0CzD8AAAAAAAAAgDOyhn98d+k/RvVD7zz+sj8PYlvxi/bPvwAAAAAAAAAAAAAAAAAAAIAA'\n",
    "    b'AAAAAAAAAAAAAAAAAACAAAAAAAAAAAAS5p+ceXSxP4Kfa3xtPuk/AAAAAAAAAICRu8tJJc/tPwAAAAAAAACAVNcnv2uq8r8AAAAA'\n",
    "    b'AAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgFqConRSR+M/qWsKZIi7+b8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAAAAAAAAA'\n",
    "    b'AAAAAAAAAAAARSt0hcOH1L+esNsN7Yn+PwAAAAAAAACAez+0wK/A3j8Itz0J1tjvv/ivP2za98a/AAAAAAAAAIAAAAAAAAAAAMVB'\n",
    "    b'rpc6rOk/hzNsPsw04D/jrFsZmwX6PwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgFLdAtr9fvi/AAAAAAAAAIAAAAAAAAAAAJkqln2f'\n",
    "    b'2t0/IChXD6IWwL+9Ou0Wx5z1Pz3sQ2fQrvO/AAAAAAAAAIDiIBDEYqMCQAAAAAAAAACAAAAAAAAAAIAAAAAAAAAAANEfbPk1BKY/'\n",
    "    b'AAAAAAAAAAAAAAAAAAAAAEvJuYm5Gt4/AAAAAAAAAIAAAAAAAAAAAAAAAAAAAACAAAAAAAAAAAB9zMZQP/PJP8BXEKpVDag/O7Yp'\n",
    "    b'MAiSwD8AAAAAAAAAAAAAAAAAAACApRbFTUOw6b8AAAAAAAAAAAG3xBTkt+y/vEFvt/tC/T+ejuHmq+/jvwAAAAAAAAAAKMW0BHXh'\n",
    "    b'1T8AAAAAAAAAgAAAAAAAAACAAAAAAAAAAICXmOxlXy7nPwAAAAAAAACAAAAAAAAAAAAAAAAAAAAAgPAWWwNPlIS/i9lVufSUz78O'\n",
    "    b'xmPOGt72v8/IkgrUPvS/3AyaWWXA5j9JW3lZsi7qvwAAAAAAAAAAAAAAAAAAAADWcSkNqkPUvwAAAAAAAACAAAAAAAAAAIAAAAAA'\n",
    "    b'AAAAAC6UQFNDQOy/SSAyS6fH/b8/A8h1B8Lnv1G0bA9o/v6/AAAAAAAAAIBUspOra+zrP+v3rx0Rmvi/',\n",
    "    shape=(COUNT_TESTS,  BATCH_SIZE, INPUT_DIM)\n",
    ")\n",
    "SOFTMAX_OUTPUTS = decode_answer(\n",
    "    b'xXhAbjms4T+kt8Giv6nQPzVFkyFmjrM/DBZi4c9ovD+9/2O0t+7iP44M7/No88I/U3O850ljyT+nBBJLubmvPxT87vyvibo/okfs'\n",
    "    b'spSinj/Z0qx5mibDP4qJX7wO8OY/l5LFH5o63z9Thj+aifG9P8BtGLOBd7U/ZXDkDCPr0z/IwiZOFI3EP5s57yGFtds/TWOx06O3'\n",
    "    b'1D/UBjCNMzG1PygFI9W5Y8I/d2S+q7Q01D+XoIyKpHKwP83wDEfFfN4/TZGKROcn2T/Z7S4nI+PdPxWaCFi/Kag/ZbYVpfa+tz/j'\n",
    "    b'y3AyoZfIPwqapYg9YrY/+uXC6quTsj8GvfaEWrvkP7TEueeHU9Q/U4IzYvzcuD9ssTWdee7hPxF+31RchJk/+H6EohVj4j+p1hFy'\n",
    "    b'9jbKP2yoaJx9abE/RtmnNfSHwz+EAnm6CdCyP3NM4EVc9dk/Phc5Ih2i1j9dt5BSCGnFP/e/vb1UidQ/etZ55g/8zD+ImpUDiLLU'\n",
    "    b'P4x035Y2jMA/EQnOG8JrwT82R0KU99O/P+R3sWe3B5E/FqlGy1Ii5z/OMhEaAWPdP0XDudD/1No/itb+kyNvoT9zvNSKami2PwTx'\n",
    "    b'EuhvENI/Gp3wsa8H2z/usO6aUlbLP6RlFGLc8rQ/puBG0pL5yT+xPT3zjBmxP2jJA2Dbs+U/oWst0OSoqj+hqzDFonKZP4UIrPFZ'\n",
    "    b'UuA/WIhcsW810j/Gt/B9ZB3HP5yWGOW8Bd0/WroVVtIvlT/YhpTupwPgP7UA0IVh/5k/orWs6WSIxz+sf3qzlWPQP3KcH9Yqm94/'\n",
    "    b'TiQ+BjT0tD/0gvjjYly3PyWmjDoWgeU/RA5ViJ4ftj/SnqZfpj3DP16af68gyMU/6Wf0OUhMxj/U69O12KfYPwkTctXyTdE/IWc2'\n",
    "    b'XM0B4j9ShSGuPi2yP3R+u6ZNrr0/z/BbMoIF0D+4D+jmodq3Pwm+Bal1rNg/IvxNqzOYzT/5P5kHyJDSP8mZuU3jR9U/d73rJi3M'\n",
    "    b'4D8+PRtUOHmmP4IOrmdtQrk/wpkNSXWMsj/UJG9Abf7pP8SFlAqk2qA/vfwurs4StT8zl5ubCdmzPyHFqQjqFdo/duHz1n72yz9X'\n",
    "    b'ZPUklPjSP8wdLsKQ99A/YYHty7gTmT/vJlfHtCvmP/PDSyai/JE/67D3fQJksT8qxg5hUlbiP3Ws7SgtYsI/amLbE4iSyz9NPV2T'\n",
    "    b'XXKbP4+nZp+yQ9Y/s4VBEkSR0D/p/iF143PXP4B2/H6DleE/eUUAMLjHsj+sRXJKPgnMP5q9m6HXPMQ/',\n",
    "    shape=(COUNT_TESTS, BATCH_SIZE, INPUT_DIM)\n",
    ")\n",
    "SOFTMAX_D_INPUTS = decode_answer(\n",
    "    b'WIS5wPxs4T/tYtAttQTgv9cCAzg36bG/Et7nguqbmj+RCJAVjLXIPzxW5KylgX2/ipaHs5Vswr9MPYXSpHOlvw2PEG2zW7y/JwA4'\n",
    "    b'6NU4ab+dTU/lBrmwP+ACBm7m2Kg/B/NST+5g3r9C2RHZsTzIP/yg5DkmurI/T7yhqBcoyz9vVDiNFadzPwpePGQmasi/iCAwIL87'\n",
    "    b'wT+C64leukSqPyixnj8Xe8I/k4hfLUpN0j9E/V2gBuGyPz0wo7qLIeC/r/IQwL1l3D/X0+Wf2/zhvxO113eJf7E/0j0mDrmgqT8m'\n",
    "    b'x0KV81DSP+DxONaMWbA/16nv9zr3tT8U7syIJeXbv6+7H1CZlbW/+coU9Og+vz+ZgoyXbui0v5nmLuc9fqY/dXkJ2kNvxL9McPuv'\n",
    "    b'eP7UP9BQ3+dJ66s/WTvl/3+IzL/IA9At1d6yv0xMvOWEcMo/2sbh6jB90b9LQ++GR/nBP/9ZUvw3m9s/GAO8VhNR3r/POg6w6VjA'\n",
    "    b'Pz3RdfZl2rW/qtEOh/cbuj+msDlAwpKyv2ydqxZGD6K/ANsKSNzmdz+QFp++o3vTPzcOtL/SJ9a/OQROdZy5ir9EPvsl3w+sP/ib'\n",
    "    b'Zs5/AsI/B6RNRqRM1D8Q8otoA47cv17+n54Y/Ie/rhdKMI9awT9+ILwcdYOuv8SymrvdwLi/aE6Spec1lT/4QPSzqMCevxRLlmqf'\n",
    "    b'Hsw/NqirnEao0b/0Gn/KBRS2Pz0YL5M80dO/jlzx7lGWgr/hgPyMrDDTP9wjolopVJM/NsC9m/sZur+zRdRP4eW3PypKj8jrO4+/'\n",
    "    b'Go/tE19umD9VAUaMLreoP73ULAeK0bw/jxu5zPBKsz99eAQNCTzOv2omI7+oHtW/OOU1Jclfx79YIGD5GNykP/oUkjIKM94/dtv2'\n",
    "    b'Bq3v2z+NWtKJvHm0v355k/lF6sW/MBBxzzW4x78PMyqAB/iYP/TdmjfU6am/gKn04JArmT+A9W3hAAFbPzf5e97n9bG/aDwuGZW5'\n",
    "    b'vL/eZWZDPuORv4vnQUQmlMk/sNL224W1mD9wTPCp6MeJPwyOtgLSt7c/IiZ5RxiPwL+Rrgnnpyinv3MTNHvFG8M/iGt/imN+nD8/'\n",
    "    b'lcHyZ+HAv31Hy8mFneG/gyw+x8uBkL80oAPJPw7jP1jqzB90lZ2/04p+0+MRnD/qQP8J1fvFv20rlcJDLJy//hTiByH/xT/qnEBS'\n",
    "    b'KCJ/P/B+GpViZ5C/eIHg7ViN07/0Jul1RhfUP8KBvfGu5bS/tIGJ1Kx4eD/V5GOKk927P2T23cve/qC/',\n",
    "    shape=(COUNT_TESTS,  BATCH_SIZE, INPUT_DIM)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR_MSG = \"Error in test {}:\\ntrue values:{},\\ndesired_values:{}\"\n",
    "\n",
    "def check_answers(actual_values, desired_values, msg=''):\n",
    "    np.testing.assert_almost_equal(actual_values, desired_values, err_msg=msg, verbose=False)\n",
    "\n",
    "def test_forward(layer, true_outputs, set_weights=False, **kwargs):\n",
    "    layer.build()\n",
    "    for i, (input, true_output) in enumerate(zip(INPUTS, true_outputs)):\n",
    "        if set_weights:\n",
    "            layer.weights = WEIGHTS[i]\n",
    "        desired_output = layer.forward(input)\n",
    "        msg = ERROR_MSG.format(i, true_output, desired_output)\n",
    "        check_answers(true_output, desired_output, msg)\n",
    "        \n",
    "def test_backward(layer, true_d_inputs, d_outputs, true_mean_d_weights=None, **kwargs):\n",
    "    layer.build()\n",
    "    for i, (input, d_output, true_d_input) in enumerate(zip(INPUTS, d_outputs, true_d_inputs)):\n",
    "        if true_mean_d_weights is not None:\n",
    "            layer.weights = WEIGHTS[i]\n",
    "        layer.forward(input)\n",
    "        desired_d_input = layer.backward(d_output)\n",
    "        check_answers(true_d_input, desired_d_input, \n",
    "                      msg=ERROR_MSG.format(i, true_d_input, desired_d_input))\n",
    "        if true_mean_d_weights is not None:\n",
    "            check_answers(true_mean_d_weights[i], layer.mean_d_weights, \n",
    "                          msg=ERROR_MSG.format(i, true_mean_d_weights[i], layer.mean_d_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_forward(Linear(OUTPUT_DIM, INPUT_DIM), LINEAR_OUTPUTS, set_weights=True)\n",
    "test_backward(Linear(OUTPUT_DIM, INPUT_DIM), LINEAR_D_INPUTS, LINEAR_D_OUTPUTS, LINEAR_MEAD_D_WEIGHTS)\n",
    "\n",
    "test_forward(ReLU(INPUT_DIM), RELU_OUTPUTS, set_weights=True)\n",
    "test_backward(ReLU(INPUT_DIM), RELU_D_INPUTS, RELU_D_OUTPUTS)\n",
    "\n",
    "test_forward(Softmax(INPUT_DIM), SOFTMAX_OUTPUTS, set_weights=True)\n",
    "test_backward(Softmax(INPUT_DIM), SOFTMAX_D_INPUTS, SOFTMAX_D_OUTPUTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Обучение нейросети стохастическим градиентным спуском"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теоретическая часть \n",
    "#### Градиентный спуск\n",
    "Настройка весов нейросети может быть сведена к поиску вектора $w$, доставляющего минимум функционалу ошибки:\n",
    "\n",
    "$$E(w) = E( \\boldsymbol{y},  \\boldsymbol{\\widehat{y}}) \\to min $$\n",
    "\n",
    "Минимизировать E(w) будем с помощью градиентного спуска. Правило изменения вектора весов на каждой итерации: \n",
    "\n",
    "$$\n",
    "w^{(k)} = w^{(k - 1)} - \\beta \\nabla_w E(w^{(k - 1)})\n",
    "$$\n",
    "Длину шага $\\beta > 0$ в рамках данного задания предлагается брать равной некоторой малой константе.\n",
    "\n",
    "В случае полного градиентного спуска $\\nabla_w E(w)$ считается все объекты выборки). В случае градиентного спуска  с минибатчем \n",
    "$$\\nabla_w E(w) \\approx \\frac{1}{n}\\sum_{j=1}^{n}{\\nabla_w q_{i_{k_j}} (w)}$$\n",
    "где $q_{i_{k_j}}$ — случайно выбранные номера слагаемых, а n меньше общего колличества примеров для обучения.\n",
    "\n",
    "#### Момент импульса(momentum)\n",
    "Может оказаться, что направление антиградиента сильно меняется от шага к шагу. Чтобы добиться болле эффективной сходимости, можно усреднять векторы антиградиента с нескольких предыдущих шагов — в этом случае шум уменьшится, и такой средний вектор будет указывать в сторону общего направления движения. Введем вектор инерции:\n",
    "    $$h_0 = 0;$$\n",
    "    $$h_k = \\alpha h_{k - 1} + \\beta \\nabla_w E(w^{(k - 1)}) $$\n",
    "Тогда шаг градиентного спуска будет:\n",
    "    $$w^{(k)} = w^{(k - 1)}  - h_k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Практическая часть\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.** Реализация стохастического градиентного спуска с моментом\n",
    "\n",
    "\n",
    "Вам необходимо реализовать алгоритм обновления весов с моментом. Для этого необходимо реализовать метод `update_weights` класса `SGD`. Также вам необходимо реализовать метод `update_weights` во всех слоях нейросети(у которых есть веса)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(object):\n",
    "    def __init__(self, lr, momentum=0, alf=0.01, bet=0.01):\n",
    "        self._lr = lr\n",
    "        self._momentum = momentum\n",
    "        self._alf = alf\n",
    "        self._bet = bet\n",
    "        if (momentum == 0):\n",
    "            alf = 0\n",
    "        self._h = 0\n",
    "\n",
    "    def update_weights(self, weights, gradient):\n",
    "        \"\"\"\n",
    "        weights: np.array((n, m)), current weigths of algorithm\n",
    "        gradient: np.array((n, m)), average gradient by weights\n",
    "        ---\n",
    "        output: np.array((n, m)), new weights values\n",
    "        \"\"\"\n",
    "        \n",
    "        self._h = self._alf * self._h + self._bet * gradient\n",
    "        weights -= self._h\n",
    "        \n",
    "        return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4.** Обучение нейросети для задачи классификации цифр mnist\n",
    "\n",
    "В этой части вам необходимо обучить вашу нейросеть для задачи классификации рукописных цифр mnist. Вам потребуются методы `fit` и `evaluate` класса `Model`. Можете использовать предложенную архитектуру или выбрать любую другую. Шаг обучения, количество эпох и размер батча выбирите на ваше усмотрение. Посчитайте ошибку и точность(accuracy) предсказания на тестовом датасете.\n",
    "\n",
    "Обучите нейросеть без момента и c моментом(выбранным на ваше усмотрение) и постройте графики ошибки во время обучения в зависимости от числа итераций. Постройте те же графики для валидационной части. Сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(images, labels):\n",
    "    binarizer = LabelBinarizer()\n",
    "    X = images.reshape((images.shape[0], 28 * 28))\n",
    "    y = binarizer.fit_transform(labels)\n",
    "    return X / 255.0, y \n",
    "\n",
    "def create_mnist_model(loss, optimizer):\n",
    "    model = Model(loss=loss, optimizer=optimizer)\n",
    "    model.add(Linear(10, input_dim=28*28))\n",
    "    model.add(ReLU())\n",
    "    model.add(Linear(10))\n",
    "    model.add(Softmax())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = prepare_data(mnist.train_images(), mnist.train_labels())\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33)\n",
    "X_test, y_test = prepare_data(mnist.test_images(), mnist.test_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train loss: 0.043313, val loss: 0.043462\n",
      "Epoch: 2, train loss: 0.033355, val loss: 0.034003\n",
      "Epoch: 3, train loss: 0.029385, val loss: 0.030721\n",
      "Epoch: 4, train loss: 0.027282, val loss: 0.029209\n",
      "Epoch: 5, train loss: 0.026047, val loss: 0.028491\n",
      "Epoch: 6, train loss: 0.025215, val loss: 0.027668\n",
      "Epoch: 7, train loss: 0.024873, val loss: 0.027684\n",
      "Epoch: 8, train loss: 0.024005, val loss: 0.027354\n",
      "Epoch: 9, train loss: 0.023368, val loss: 0.026778\n",
      "Epoch: 10, train loss: 0.023272, val loss: 0.026830\n",
      "accuracy model without momentum 0.9263\n",
      "Epoch: 1, train loss: 0.035570, val loss: 0.036104\n",
      "Epoch: 2, train loss: 0.029589, val loss: 0.030686\n",
      "Epoch: 3, train loss: 0.027577, val loss: 0.029308\n",
      "Epoch: 4, train loss: 0.025707, val loss: 0.027529\n",
      "Epoch: 5, train loss: 0.025189, val loss: 0.027400\n",
      "Epoch: 6, train loss: 0.023790, val loss: 0.026363\n",
      "Epoch: 7, train loss: 0.023107, val loss: 0.025882\n",
      "Epoch: 8, train loss: 0.022355, val loss: 0.025402\n",
      "Epoch: 9, train loss: 0.022696, val loss: 0.025736\n",
      "Epoch: 10, train loss: 0.021429, val loss: 0.024906\n",
      "accuracy model with momentum 0.9327\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xd8VFXex/HPLx1IAUJIQk0IKCWEXhUEqQoW1gJ21MV1LVtc66PrKuuuqLuru8/6uGsXF7uoWFkLKghSDTWgdEJPaAkh/ff8cW/CEAIMMJOZJL/36zWvzL1z7rlnsm6+3HPPPUdUFWOMMcbXQgLdAGOMMXWTBYwxxhi/sIAxxhjjFxYwxhhj/MICxhhjjF9YwBhjjPELCxhjahERGSIi2YFuhzHesIAxxhjjFxYwxhhj/MICxpgAEJF7ROSdKvv+LiL/EJHrRSRLRPJEZL2I/CJQ7TTmdFjAGBMYbwDni0gMgIiEApcDrwG7gLFALHA98KSI9AxUQ405VRYwxgSAqm4ClgDj3F3nAgWq+r2qfqyq69TxDfBfYFCg2mrMqbKAMSZwXgOucN9f6W4jIueJyPciskdE9gHnA80C1EZjTpkFjDGB8zYwRERa4VzJvCYikcC7wF+ARFVtDHwCSOCaacypsYAxJkBUdTfwNfASsEFVs4AIIBLYDZSKyHnAyIA10pjTYAFjTGC9Bgx3f6KqecCvgLeAvThdZzMC1jpjToPYgmPGGGP8wa5gjDHG+IUFjDHGGL+wgDHGGOMXFjDGGGP8IizQDQikZs2aaUpKSqCbYYwxtcrixYtzVDXhROXqdcCkpKSwaNGiQDfDGGNqFRHZ5E056yIzxhjjFxYwxhhj/MICxhhjjF/U63swxvhaSUkJ2dnZFBYWBropxpy2qKgoWrVqRXh4+CkdbwFjjA9lZ2cTExNDSkoKIjYBsqm9VJXc3Fyys7NJTU09pTqsi8wYHyosLCQ+Pt7CxdR6IkJ8fPxpXY1bwBjjYxYupq443f+WLWBOwZLNe3nss9WBboYxxgQ1C5hTsHLrfp75eh0/7swLdFOMMSZoWcCcglHpSYQIfLRse6CbYsxRoqOjA92EI0ycOJF33nnnlI9/8MEH+eKLLwB46qmnKCgoqPzMV99148aNvPbaaz6pq6ZlZmbyySefBLoZ1bKAOQXNY6LolxrPx8u2YQu2GeNfkydPZvjw4cDRAeMrFjD+YcOUT9GYjGQeeH8Fa3bm0TEpNtDNMUHo4Q9XsmrbAZ/W2blFLH+4oItXZVWVu+++m08//RQR4YEHHmD8+PFs376d8ePHc+DAAUpLS3nmmWcYOHAgN954I4sWLUJEuOGGG/jtb397VJ2rV6/m2muvZcGCBYDzh/mCCy5g+fLlTJ48mQ8//JBDhw4xcOBA/v3vf5/wJvHChQt59NFHmT59Oh988AETJkxg//79lJeX07lzZ9avX8/EiRMZO3Ys27ZtY9u2bQwdOpRmzZoxa9YsAO6//34++ugjGjRowAcffEBiYiIbN27khhtuICcnh4SEBF566SXatGlTWdell14KOFdA+fn53HvvvWRlZdG9e3euu+66ar/7yy+/zPvvv8/Bgwf56aefuPPOOykuLubVV18lMjKSTz75hKZNm5KZmcnNN99MQUEBaWlpvPjiizRp0oQhQ4bQo0cPZs+ezcGDB5k6dSqPPvooy5cvZ/z48TzyyCNs3LiRsWPHsmLFCgD+8pe/kJ+fz0MPPcSQIUPo168fs2bNYt++fbzwwgv069ePBx98kEOHDjFnzhzuu+8+srKyiI6O5s477wQgPT2djz76CIDRo0fTv39/5s6dS58+fbj++uv5wx/+wK5du5g2bRp9+/b16r8tb9kVzCka7XaTfWzdZCZITZ8+nczMTJYuXcoXX3zBXXfdxfbt23nttdcYNWpU5Wfdu3cnMzOTrVu3smLFCpYvX871119fbZ0dO3akuLiYDRs2APDmm28yfvx4AG677TYWLlzIihUrOHToUOUftePp0aMHmZmZAMyePZv09HQWLlzI/Pnz6dev3xFlf/WrX9GiRQtmzZpVGS4HDx6kf//+LF26lMGDB/Pcc88BcPvtt3PdddexbNkyrrrqKn71q18dtx1Tpkxh0KBBZGZmVhsuFVasWMH06dNZuHAh999/Pw0bNuSHH35gwIABTJ06FYBrr72Wxx57jGXLltG1a1cefvjhyuMjIiJYtGgRN998MxdddBFPP/00K1as4OWXXyY3N/eEv6/S0lIWLFjAU089xcMPP0xERASTJ09m/PjxZGZmVv5vcSxr167ld7/7HatXr2b16tW89tprzJkzh7/85S/8+c9/PuH5T5ZdwZyiZtGRDEiL5+Nl27ljxBk2NNUcxdsrDX+ZM2cOV1xxBaGhoSQmJnLOOeewcOFC+vTpww033EBJSQkXX3wx3bt3p127dqxfv57bb7+dMWPGMHLkyGPWe/nll/Pmm29y77338uabb/Lmm28CMGvWLB5//HEKCgrYs2cPXbp04YILLjhuG8PCwkhLSyMrK4sFCxZwxx138O2331JWVsagQYNO+B0jIiIYO3YsAL169eLzzz8HYN68eUyfPh2Aa665hrvvvtur39mJDB06lJiYGGJiYoiLi6v8fl27dmXZsmXs37+fffv2cc455wBw3XXXcdlll1Uef+GFF1aW79KlC8nJyQC0a9eOLVu20Lhx4+Oe/2c/+1nld924ceNJtz81NZWuXbsC0KVLF4YNG4aI0LVr11Oq70TsCuY0jOnagvU5B8nabqPJTO0xePBgvv32W1q2bMnEiROZOnUqTZo0YenSpQwZMoR//etf/PznPz/m8ePHj+ett97ixx9/RETo0KEDhYWF3HLLLbzzzjssX76cSZMmef2A3uDBg/n0008JDw9n+PDhzJkzhzlz5ngVMOHh4ZX/uAsNDaW0tPS45cPCwigvLwegvLyc4uJir9pYITIysvJ9SEhI5XZISMgJz+15vOexnsd7tg846ndYcczxvuvx6jjd9p8svwaMiIwWkTUislZE7q3m80gRedP9fL6IpFT5vI2I5IvIne52axGZJSKrRGSliPzao+xDIrJVRDLd1/n+/G4Ao7okEhoifLx8m79PZcxJGzRoEG+++SZlZWXs3r2bb7/9lr59+7Jp0yYSExOZNGkSP//5z1myZAk5OTmUl5dzySWX8Mgjj7BkyZJj1puWlkZoaCh//OMfK7tkKv6INWvWjPz8/JMaNTZo0CCeeuopBgwYQEJCArm5uaxZs4b09PSjysbExJCXd+J/0A0cOJA33ngDgGnTplWGVUpKCosXLwZgxowZlJSUnFS9JxIXF0eTJk2YPXs2AK+++mrl1Yw3EhMT2bVrF7m5uRQVFXnVzVi17SkpKZX/+y1ZsqSyOzMQ/NZFJiKhwNPACCAbWCgiM1R1lUexG4G9qtpeRCYAjwGenYh/Az712C4FfqeqS0QkBlgsIp971Pmkqv7FX9+pqvjoSAa63WR3jjzTuslMUBk3bhzz5s2jW7duiAiPP/44SUlJvPLKKzzxxBOEh4cTHR3N1KlT2bp1K9dff33lv3wfffTR49Y9fvx47rrrrso/Xo0bN2bSpEmkp6eTlJREnz59vG5nv3792LlzJ4MHDwYgIyODHTt2VPv/p5tuuonRo0dX3os5lv/93//l+uuv54knnqi8yQ8wadIkLrroIrp168bo0aNp1KhR5TlDQ0Pp1q0bEydOPO59mBN55ZVXKm/yt2vXrvLc3ggPD+fBBx+kb9++tGzZko4dO57wmKFDhzJlyhS6d+/OfffdxyWXXMLUqVPp0qUL/fr144wzzjjl73K6xF/DbEVkAPCQqo5yt+8DUNVHPcrMdMvME5EwYAeQoKoqIhcDZwEHgfzqgkNEPgD+qaqfi8hDxyp3LL1799bTXdHy9QWbuW/6cj66/WzSW8adVl2m9svKyqJTp06BboYxPlPdf9MislhVe5/oWH92kbUEtnhsZ7v7qi2jqqXAfiBeRKKBe4CHOQa3O60HMN9j920iskxEXhSRJsc47iYRWSQii3bv3n1y36gao7okERoifLLcRpMZY4ynYL3J/xBOd1d+dR+6AfQu8BtVrXjQ4BkgDegObAf+Wt2xqvqsqvZW1d4JCQmn3dCmjSKcbrLl2+2hS1On3HrrrXTv3v2I18l091Q1bty4o+qbOXOmD1vsGzNnzjyqnePGjQt0s2olfw5T3gq09thu5e6rrky220UWB+QC/YBLReRxoDFQLiKFqvpPEQnHCZdpqjq9oiJV3VnxXkSeA058d8xHxmYkc8+7y1m57YB1k5k64+mnn/Zpfe+9955P6/OXUaNGMWrUqEA3o07w5xXMQqCDiKSKSAQwAZhRpcwM4Dr3/aXAV+oYpKopqpoCPAX82Q0XAV4AslT1b54ViUiyx+Y4YIXvv1L1RnZOIixEbG4yY4zx4LeAce+p3AbMBLKAt1R1pYhMFpEL3WIv4NxzWQvcARw1lLmKs4BrgHOrGY78uIgsF5FlwFDg1IeBnKQmjSI4q30zPl5uc5MZY0wFvz7Jr6qfAJ9U2fegx/tC4LKqx1Up/5DH+zlAtWOBVfWa02nr6RqTkczd7yxj+db9ZLQ6/tO4xhhTHwTrTf5aZ1TnJMJDxeYmM8YYlwWMj8Q1DOfs9s34aJmNJjOBZevB1C7vv/8+q1atOnHBWsgCxofGZLRg675DLM3eH+imGFNn1MR6MIFkAWO8MqJzottNZnOTGeDTe+GlMb59fXqicTCHqSp33XUX6enpdO3atXLW4+3btzN48GC6d+9Oeno6s2fPpqysjIkTJ1aWffLJJ6utc/Xq1UesGbJx48bK2XknT55Mnz59SE9P56abbvLqSn7hwoWVMwR/8MEHNGjQgOLiYgoLC2nXrh1w+AroH//4R+V6MEOHDq2s4/7776dbt27079+fnTt3Vnueinp++ctf0r9/f9q1a8fXX3/NDTfcQKdOnZg4cWJluddff52uXbuSnp7OPffcU7k/Ojqau+66iy5dujB8+HAWLFjAkCFDaNeuHTNmOANkX375ZW677bbKY8aOHcvXX39deXzVts6dO5cZM2Zw11130b17d9atW8eQIUOomGEkJyeHlJSUyrovvvhiRowYQUpKCv/85z/529/+Ro8ePejfvz979uw54e+7plnA+FBcg3AGd0jgY+smM0GgPq8Hcyx79+5l3rx5PPnkk1x44YX89re/ZeXKlSxfvpzMzEy2bdvGPffcw1dffUVmZiYLFy7k/fffrzzXueeey8qVK4mJieGBBx7g888/57333uPBBx887nmP1daBAwdy4YUX8sQTT5CZmUlaWtpx6/BmPZpgYuvB+Nj5XZP5cvUuftiyj55tqp2txtQX500J6Onr83owx3LBBRdUrn+SmJh4xNooGzduZNOmTQwZMoSKWT6uuuoqvv32Wy6++GIiIiIYPXo04KznEhkZSXh4uNdrqZxsW6tzovVogo1dwfjY8M6JRISG2GgyE7Tq83owJ1qPxdtzHWstleOtxeJtWz3rONZ6MMdrQzCxgPGxuAbhDD6jGZ8u3055uXWTmcCpz+vBnKq+ffvyzTffkJOTQ1lZGa+//vpJreeSkpJCZmYm5eXlbNmyhQULFpzwmOrWc6lYs+Z0Rt8FA+si84MxGcl8keV0k/Vqa91kJjDq83owpyo5OZkpU6YwdOhQVJUxY8Zw0UUXeX38WWedRWpqKp07d6ZTp0707NnzhMdMmDCBSZMm8Y9//IN33nmHO++8k8svv5xnn32WMWPGnM7XCTi/rQdTG/hiPZjq5BWW0OuRL7i6X1sevKCzz+s3wcvWgzF1TbCuB1NvxUSFc84ZCXxi3WTGmHrMusj8ZGxGMp+v2smSzXvpndI00M0x5qTdeuutfPfdd0fs+/Wvf33MIcwnMm7cuKPWh3/sscd8PjX+n/70J95+++0j9l122WXcf//9Pj2POTHrIvNDFxlAflEpPf/4OVf2bcNDF3bxyzlM8MnKyqJjx47V3j8wprZRVVavXm1dZMEmOjKMoWdaN1l9ExUVRW5urj1oa2o9VSU3N5eoqKhTrsO6yPxoTEYLZq7cyaJNe+mbat1k9UGrVq3Izs5m9+7dgW6KMactKiqKVq1anfLxFjB+NKxjcyLDQvh42TYLmHoiPDyc1NTUQDfDmKBgXWR+1CgyjKFnNueTFTsos24yY0w9YwHjZ2MyktmdV8TCjcE306kxxviTXwNGREaLyBoRWSsiR80zLiKRIvKm+/l8EUmp8nkbEckXkTtPVKeIpLp1rHXrjPDnd/PWuR2bExVuc5MZY+ofvwWMiIQCTwPnAZ2BK0Sk6mPtNwJ7VbU98CTwWJXP/wZ86mWdjwFPunXtdesOuEaRYZzbsTmfWjeZMaae8ecVTF9graquV9Vi4A2g6qQ+FwGvuO/fAYaJ+wCBiFwMbABWnqhO95hz3Tpw67zYD9/plIzp2oKc/CIWbLBuMmNM/eHPgGkJbPHYznb3VVtGVUuB/UC8iEQD9wAPe1lnPLDPreNY5wJARG4SkUUisqimhpIO7ZhAg/BQPl5uK10aY+qPYL3J/xBOd1e+rytW1WdVtbeq9q5YVMjfGkaEcW6n5ny2YgelZeUnPsAYY+oAfwbMVqC1x3Yrd1+1ZUQkDIgDcoF+wOMishH4DfA/InLbcerMBRq7dRzrXAE1tmsyOfnF1k1mjKk3/BkwC4EO7uiuCGACMKNKmRnAde77S4Gv1DFIVVNUNQV4Cvizqv7zWHWqMy/HLLcO3Do/8ON3O2lDzmxOw4hQPlpuo8mMMfWD3wLGvR9yGzATyALeUtWVIjJZRC50i72Ac89lLXAHcNRQZm/qdD++B7jDrSverTtoNIgIZVinROsmM8bUGzabsp9mU67OZyt2cPN/FvOfG/txdodmNXZeY4zxJZtNOQgNOTOBRhE2mswYUz9YwNSgqPDD3WQl1k1mjKnjLGBq2JiMZPYWlDBvXW6gm2KMMX5lAVPDzjnD7SazucmMMXWcBUwNiwoPZUTnRD5bad1kxpi6zQImAMZktGD/oRK+W5sT6KYYY4zfWMAEwKAOzYiJDOMTe+jSGFOHWcAEQEU32cyVOykutW4yY0zdZAETIGMykp1usnXWTWaMqZssYALk7A7NiIkKs9Fkxpg6ywImQCLDQhnZOYmZK3dYN5kxpk6ygAmgsRnJ5BWWMmdtzSx8ZowxNckCJoDOat+M2KgwPrJuMmNMHWQBE0ARYSGM7JLE5yt3UlRaFujmGGOMT1nABNiYjGTyikqZ/aONJjPG1C0WMAF2Vloz4hqE87E9dGmMqWMsYAIsIiyEUV0S+XzVTgpLrJvMGFN3WMAEgTEZLcgvKuXbH200mTGm7vBrwIjIaBFZIyJrReTeaj6PFJE33c/ni0iKu7+viGS6r6UiMs7df6bH/kwROSAiv3E/e0hEtnp8dr4/v5svDUyLp3FD6yYzxtQtYf6qWERCgaeBEUA2sFBEZqjqKo9iNwJ7VbW9iEwAHgPGAyuA3qpaKiLJwFIR+VBV1wDdPerfCrznUd+TqvoXf30nfwkPDWF0lyQ+XLqNwpIyosJDA90kY4w5bf68gukLrFXV9apaDLwBXFSlzEXAK+77d4BhIiKqWqCqpe7+KECrqX8YsE5VN/mh7TVuTEYyB4vL+Ma6yYwxdYQ/A6YlsMVjO9vdV20ZN1D2A/EAItJPRFYCy4GbPQKnwgTg9Sr7bhORZSLyoog0qa5RInKTiCwSkUW7dwfPH/MB7eJp0jDc5iYzxtQZQXuTX1Xnq2oXoA9wn4hEVXwmIhHAhcDbHoc8A6ThdKFtB/56jHqfVdXeqto7ISHBb+0/WWGhIYxOT+aLLBtNZoypG/wZMFuB1h7brdx91ZYRkTAgDsj1LKCqWUA+kO6x+zxgiaru9Ci3U1XLVLUceA6ni65WGZuRTEFxGV+v2RXophhjzGnzZ8AsBDqISKp7xTEBmFGlzAzgOvf9pcBXqqruMWEAItIW6Ahs9DjuCqp0j7mDASqMwxkoUKv0S21KfKMIm5vMGFMn+G0UmTsC7DZgJhAKvKiqK0VkMrBIVWcALwCvishaYA9OCAGcDdwrIiVAOXCLquYAiEgjnJFpv6hyysdFpDvOgICN1Xwe9MJCQxiVnsR7S7ZyqLiMBhE2mswYU3uJanUDtOqH3r1766JFiwLdjCPMXZvDlc/P5/+u6sn5XZNPfIAxxtQwEVmsqr1PVC5ob/LXV31Tm9IsOsJGkxljaj0LmCDjjCZL4svVOykorjoy2xhjag8LmCA0pmsLCkvK+Wq1jSYzxtReFjBByOkmi7RuMmNMrWYBE4RCQ4TzuyYxa80uDhZZN5kxpnaygAlSY7omWzeZMaZWs4AJUr1TmtI8xrrJjDG1lwXMqSgvhx3L/XoKp5ssmVlrdpFv3WTGmFrIAuZUfP0oPDcM9m7062nGZCRTVFrOl1k7T1zYGGOCjAXMqeh1HYSEwn8f8O9p2jQhMda6yYwxtZMFzKmIawWD7oCsD2HdLL+dJiREOC89ma9/3E1eYYnfzmOMMf5gAXOqBtwOjdvCZ/dCmf/++I/NSKa4tJwvs2w0mTGmdrGAOVXhUTD6Udi9GhY+77fT9GzThKTYKJvC3xhT61jAnI4zz4e0c2HWo5Dvn+WXQ9zRZN/+uJsD1k1mjKlFLGBOhwiMngIlB+GryX47zZiMZIrLyvlilY0mM8bUHhYwpyvhTOh3Myx5FbYu8csperRuTIu4KBtNZoypVSxgfOGcu6FRM/j0HuchTB+r7Cb7aTf7D1k3mTGmdvBrwIjIaBFZIyJrReTeaj6PFJE33c/ni0iKu7+viGS6r6UiMs7jmI0istz9bJHH/qYi8rmI/OT+bOLP73aEqDgY/hBkL4Dlb/nlFGMykikpU+smM8bUGn4LGBEJBZ4GzgM6A1eISOcqxW4E9qpqe+BJ4DF3/wqgt6p2B0YD/xaRMI/jhqpq9ypLdt4LfKmqHYAv3e2a0+1KaNETPv8DFOX5vPrurRvTsnEDPl5u3WTGmNrBn1cwfYG1qrpeVYuBN4CLqpS5CHjFff8OMExERFULVLViAq4oQL04n2ddrwAXn1brT1ZICJz/BOTvgG//4vPqRYQxGcnM/mk3+wusm8wYE/z8GTAtgS0e29nuvmrLuIGyH4gHEJF+IrISWA7c7BE4CvxXRBaLyE0edSWqasU/73cAidU1SkRuEpFFIrJo924fDy1u1Ru6XwXznobcdb6tG2cK/5Iy5b+rdvi8bmOM8bWgvcmvqvNVtQvQB7hPRKLcj85W1Z44XW+3isjgao5VjnHVo6rPqmpvVe2dkJDg+4YP+wOERcFn9/m86oxWcbRqYt1kxpjawZ8BsxVo7bHdyt1XbRn3HksckOtZQFWzgHwg3d3e6v7cBbyH0xUHsFNEkt26koHAzK0SkwhD7oGfZsKPM31atYgwpmsyc37KYV9BsU/rNsYYX/MqYETk1yISK44XRGSJiIw8wWELgQ4ikioiEcAEYEaVMjOA69z3lwJfqaq6x4S5524LdAQ2ikgjEYlx9zcCRuIMCKha13XAB958N7/o+wuI7+BcxZQW+bTqMRnJlJYr/11po8mMMcHN2yuYG1T1AM4f9CbANcCU4x3g3jO5DZgJZAFvqepKEZksIhe6xV4A4kVkLXAHh0d+nQ0sFZFMnKuUW1Q1B+e+yhwRWQosAD5W1c/cY6YAI0TkJ2D4idrnV2ERzhP+e9bB98/4tOquLeNo3bQBH1k3mTEmyIWduAgA4v48H3jVDQo53gEAqvoJ8EmVfQ96vC8ELqvmuFeBV6vZvx7odoxz5QLDTtSmGtNhuDNX2bdPQMZ4iE32SbVON1kLnpu9nr0Hi2nSKMIn9RpjjK95ewWzWET+ixMwM91uKt8/sl7XjPoTlBXDFw/5tNqxGcmUlSszV9poMmNM8PI2YG7E6b7qo6oFQDhwvd9aVVc0bQcDb4dlb8Dm+T6rtkuLWNrGN7TRZMaYoOZtwAwA1qjqPhG5GngA55kVcyJn3wExLeDTu6G8zCdVVowmm7sul9x83w4iMMYYX/E2YJ4BCkSkG/A7YB0w1W+tqksio2HkH2F7JvzwH59VO6aym8xGkxljgpO3AVPqPrx4EfBPVX0aiPFfs+qY9EugzQD48mE4tM8nVXZOjiW1WSPeWbyFsnJvZtIxxpia5W3A5InIfTjDkz8WkRCc+zDGGyJw3uNwaC987ZvR0yLCpEHtWLJ5H3e9s5RyCxljTJDxNmDGA0U4z8PswHkq/wm/taouSs6AXhNhwbOwK8snVV7Zrw13jDiD6Uu2cv/7y3EuMo0xJjh4FTBuqEwD4kRkLFCoqnYP5mQNfQAiY5yFyXwUBref255bh6bx+oItPPzhKgsZY0zQ8HaqmMtxnpy/DLgcmC8il/qzYXVSo3g49wHY8A1kfeiTKkWEO0eeyY1np/Ly3I1M+XS1hYwxJih4+yT//TjPwOwCEJEE4AucNVzMyeh1PSx6CWbeDx1GQHiD065SRHhgTCeKSsv497friQwP5Y4RZ/igscYYc+q8vQcTUhEurtyTONZ4Cg2D8x6D/Zvhu3/4rFoRYfKF6VzeuxX/+PInnp611md1G2PMqfD2CuYzEZkJvO5uj6fKHGPmJKQOgi7jYM7foPsV0LiNT6oNCREe/VkGRaXlPDFzDZFhIfx8UDuf1G2MMSfL25v8dwHPAhnu61lVvcefDavzRvwREPjv731abWiI8NfLunFeehKPfJzFq99v8mn9xhjjLW+vYFDVd4F3/diW+qVxaxh0B8z6E2z4FlKPWpjzlIWFhvD3CT0ombaY37+/gsjQEC7v0/rEBxpjjA8d9wpGRPJE5EA1rzwROVBTjayzBt7udI99eg+Ulfq06oiwEP55ZU8GdWjGPdOX8UFm1cVEjTHGv44bMKoao6qx1bxiVDW2phpZZ4U3gFF/hl2rYNGLPq8+KjyUZ6/pTb/Uptzx1lI+tdmXjTE1yEaCBVrHsdBuCMx6BA7m+rz6BhGhvHBdH7q3bsztr//AF6tsckxjTM2wgAk0ERj9GBTlw1d/9Mu3N7MwAAAgAElEQVQpGkWG8dL1fejcIpZbpi3h2x93++U8xhjjya8BIyKjRWSNiKwVkXur+TxSRN50P58vIinu/r4ikum+lorIOHd/axGZJSKrRGSliPzao66HRGSrx3Hn+/O7+VTzjtDvF7D4Zdi+1C+niI0KZ+oNfUlrHs2kqYuYt873V0vGGOPJbwEjIqHA08B5QGfgChHpXKXYjcBeVW0PPAk85u5fAfRW1e7AaODfIhIGlAK/U9XOQH/g1ip1Pqmq3d1X7XpO55x7oGE8fHK3z+Ypq6pxwwj+c2Nf2jRtyI2vLGTxpj1+OY8xxoB/r2D6AmtVdb2qFgNv4Kwn4+ki4BX3/TvAMBERVS1Q1YphVVGAAqjqdlVd4r7PA7KAln78DjWnQWMY/gfY8j0s998MPPHRkUyb1I/E2CgmvriQpVt8sz6NMcZU5c+AaQls8djO5ugwqCzjBsp+IB5ARPqJyEpgOXCzR+Dgfp4C9AA8F7u/TUSWiciLItKkukaJyE0iskhEFu3eHWT3IrpfDS16wOcPOvdk/KR5TBSvTepH40bhXPviAlZtsxHnxhjfC9qb/Ko6X1W7AH2A+0QkquIzEYnGeejzN6pa8dfxGSAN6A5sB/56jHqfVdXeqto7ISHBr9/hpIWEOAuT5W1zppHxo+S4Brz28/40igjl6hfm89POPL+ezxhT//gzYLYCno+Pt3L3VVvGvccShzORZiVVzQLygXS3XDhOuExT1eke5XaqapmqlgPP4XTR1T6t+0K3K2Du/8Ke9f49VdOGTJvUn7AQ4crn57N+t/+umowx9Y8/A2Yh0EFEUkUkApgAzKhSZgZwnfv+UuArVVX3mDAAEWkLdAQ2iogALwBZqnrEP/FFJNljcxzOQIHaafhDEBrhTOnvZ6nNGjHt5/0oL1euen4+W/YU+P2cxpj6wW8B494zuQ2YiXMz/i1VXSkik0XkQrfYC0C8iKwF7gAqhjKfDSwVkUzgPeAWVc0BzgKuAc6tZjjy4yKyXESWAUOB3/rru/ldTBKcczes+QR++sLvp+uQGMOrN/ajoLiMK577nm37Dvn9nMaYuk/q8+qHvXv31kWLFgW6GdUrLYZnBgACv5wLYRF+P+Wy7H1c9dx84qMjeOsXA2geG3Xig4wx9Y6ILFbV3icqF7Q3+eu9sAgYPQVyf4IF/66RU2a0aszLN/RlV14RVz4/n5z8oho5rzGmbrKACWYdRsAZo+HrxyCvZuYQ69W2CS9O7EP23gKufn4++wqKa+S8xpi6xwIm2I36M5QVwZcP19gp+7eL57lre7M+5yDXvLCAA4UlNXZuY0zdYQET7OLTYMCtkDkNsmvuftGgDgk8c1VPVu84wMQXF5Bf5Nv1aowxdZ8FTG0w6E6ISYZP7oLy8ho77bBOifzvFT1Ymr2fG19eyKHisho7tzGm9rOAqQ0io2HEZNi2BJa+VqOnHp2ezN8u78aCjXu46dVFFJZYyBhjvGMBU1t0vQxa94MvHoLC/TV66ou6t+TxSzKY/VMOt05bQnFpzV1FGWNqLwuY2kLEmafsYA5883iNn/6y3q155OJ0vly9i1+9/gOlZRYyxpjjs4CpTVp0h17Xwfx/we41NX76q/u35fdjO/PZyh3c8dZSysrr70O6xpgTs4Cpbc79PUQ0gs/u9dvCZMdz49mp3DO6IzOWbuPed5dRbiFjjDkGC5japlEzGHo/rPvKmassAH45JI1fD+vA24uz+f0HK6jP0w0ZY47NAqY26n0jJHSCz+6DksKANOE3wztw8zlpTJu/mT9+lGUhY4w5igVMbRQaBuc9Bvs2wTdTavTZmAoiwj2jz+T6s1J48bsN3PHWUjblHqzxdhhjgldYoBtgTlG7cyD9UpjzJKx8H/r9ArpfBVGxNdYEEeHBsZ1pEB7K87M38EHmVi7o1oJfDkmjY1LNtcMYE5xsuv5gna7fG2WlsPpD+P5fsOV7iIiBHldB35ucKWZq0K4DhTw/ZwP/+X4TBcVlDO+UyK1D0+jRpkmNtsMY43/eTtdvAVObA8bT1iXO8OUV06G8FM4YBf1uhnZDnGdoasi+gmJenruRl77byP5DJQxMi+fWoe0ZmBaP1GA7jDH+YwHjhToVMBXydsCiF53Xwd3OYIB+v4CM8RDRsMaakV9UyuvzN/Pc7PXsyiuiW+vG3DokjeGdEgkJsaAxpjYLioARkdHA34FQ4HlVnVLl80hgKtALyAXGq+pGEekLPFtRDHhIVd87Xp0ikgq8AcQDi4FrVPW4i5nUyYCpUFoEK96F75+BHcugQRPoeR30nQRxrWqsGYUlZby7JJt/fbOOLXsOcUZiNLcMac/YjGTCQm2MiTG1UcADRkRCgR+BEUA2sBC4QlVXeZS5BchQ1ZtFZAIwTlXHi0hDoFhVS0UkGVgKtAD0WHWKyFvAdFV9Q0T+BSxV1WeO18Y6HTAVVGHzPCdoVn8ECHS6APr/0pnbrIa6rUrLyvlo2Xb+7+u1/Lgzn9ZNG3DzOWlc0rMVUeGhNdIGY4xvBEPADMC58hjlbt8HoKqPepSZ6ZaZJyJhwA4gQT0a5V6ZfA+0BPpUVycwBdgNJLmhdMS5j6VeBIynfZthwXOw5BVnwszk7k7QdPmZs0RzDSgvV77I2snTX69j6ZZ9NI+JZNKgdlzZrw2NIm1QozG1gbcB488+ipbAFo/tbHdftWVUtRTYj9PFhYj0E5GVwHLgZvfzY9UZD+xzyxzrXKZxGxj5R7gjC8b8FUoK4L1fwFPpzrLM+bv83oSQEGFklyTev2Ug037ej/bNo/nTJ1mc9dhXPPXFj7ZEszF1SNB2gqvqfFXtgnPVcp+IRPmiXhG5SUQWicii3bt3+6LK2ieiEfT5OdwyH65+F5Iy4Os/w5Nd4L1fwvalfm+CiHBW+2a8Nqk/028ZSO+2TXnqi584a8pX/PmTLHYdCMwMBcYY3/Fnn8RWoLXHdit3X3Vlst0usjicm/2VVDVLRPKB9OPUmQs0FpEw9yqmunNV1Pcs7gCC3r17198hdAAhIdB+uPPK+Qnm/xsyX3MWNWszEPrfDGeOcWYO8KOebZrw/HW9Wb3jAM98vY7nZ6/n5bkbuaxXK34xOI028TU3+s0Y4zv+vAcThnNDfhjOH/uFwJWqutKjzK1AV4+b/D9T1cvd+y5b3PspbYF5QAaw71h1isjbwLseN/mXqer/Ha+N9e4ejDcO7YMfXoUFzzr3bOJaOyPPel7rjESrAZtyD/Kvb9bz7uJsylS50J0d4IzEmBo5vzHm+AJ+k99txPnAUzhDil9U1T+JyGRgkarOcLu9XgV6AHuACaq6XkSuAe4FSoByYLKqvn+sOt397XCGKTcFfgCuVtWi47XPAuY4ysuc2Zq//xdsmgPhDaHbBOfhzYQza6QJO/YX8vzs9Uybv5lDJWWM7JzIrUPb06114xo5vzGmekERMMHOAsZL25c53WfL34ayIkgb5ow+SxvmdLP52d6Dxbw0dyMvf7eBA4WlnN2+GbcMTWNAO5sdwJhAsIDxggXMSTqYA4tegoXPQ/4OiG8PfX8B3a+EyGi/nz6/qJRp32/iudkbyMkvokebxtw6pD3DOjW3oDGmBlnAeMEC5hSVFsOqD2D+M7B1MUTGOvdpzvpNjczmXFhSxtuLs/n3N+vI3nuIjkkx/HJIGmO62uwAxtQECxgvWMD4wJaFMO+fsOp9aJQAQ/8Helzr95FnACVl5Xy4dBv/9/U61u7Kp218Q8ZmJNOrbRN6tG5Ck0Y18/CoMfWNBYwXLGB8aOtimHm/My1NQicY9Ygz/LkGlJcr/121kxfmrGfJ5n2UlTv/TbdLaESvNk3o1dZ5pSVE20SbxviABYwXLGB8TBWyPoTPH4S9G5xBACMfgcTONdaEguJSlmXvZ8nmvSzZtJfFm/ayt6AEgNioMHq2bUJPN3S6tW5MtE1PY8xJs4DxggWMn5QWw8Ln4JvHoCjPeYZm6P0Q3bzGm6KqbMg5yOJNe1my2QmcH3fmAxAi0DEptvIKp2ebJrRu2sAGDBhzAhYwXrCA8bOCPfDN407YhEXB2b+FAbdCeIOANmv/oRIyt+xzQmfTXn7YvJeDxWUANIuOpFfbxpWh06VFnM32bEwVFjBesICpITlr4Ys/OMsFxLaCYQ9C18tq5Bkab5SVK2t25LF4815+2LSXxZv3sim3AICI0BC6tIw94l5O81ifTItnTK1lAeMFC5gatnGOMxBgeya06AGj/gxtBwa6VdXanVd0xH2cZVv3U1xaDkCrJg2O6FbrmBRjw6NNvWIB4wULmAAoL4flb8GXk+HAVmfxs+EPQ3xaoFt2XEWlZazadqDyXs6ijXvZlefMRNQwIpRurQ53q/Vo05jGDW2ItKm7LGC8YAETQMUFMO9pmPMklBU7D2oOvgsaNg10y7yiqmzdd6jyPs7izXvJ2p5XOUS6U3IsA9PiGZgWT9/UpsREhQe4xcb4jgWMFyxggkDeTpj1J2cG58hYOOceZ62aGlph05cKiktZumU/izbuYd76XBZt2ktxaTmhIUJGqzjOSmvGwLR4erZtYgMHTK1mAeMFC5ggsnOlc39m/Sxo2g5GTIaOY6EWDxkuLCljyaa9zF2Xy3frcliWvZ+yciUiLITebZs4Vzjtm5HRMs7u4ZhaxQLGCxYwQUYV1n4B/30Adq+Gtmc5D2q27BnolvlEXmEJCzbsYe66XOauyyVr+wEAoiPD6Jva1O1Sa0bHpBibccAENQsYL1jABKmyUvhhKnz1JyjIgYwJMOz3ENcq0C3zqdz8Ir5fv4e563KYuy6XDTkHAWjaKIIB7eIZ4N7DSW3WyB7+NEHFAsYLFjBBrvCAMwhg3tNOV9nA2+GsX0Nk3VzZctu+Q8xzu9Pmrs1lx4FCAJLjohiQFu/cw2kfT3JcYB9UNcYCxgsWMLXEvs3OsOblb0Oj5nDu/dDjGgipuzfKVZWNuQV8tzaHeetymbsup3JOtdRmjSq70/q3a0p8dGSAW2vqGwsYL1jA1DLZi2Hm/8CW76F5Fxj5R2g/LNCtqhHl5crqHXnMXecEzvwNe8gvKgVsSLSpeUERMCIyGvg7EAo8r6pTqnweCUwFegG5wHhV3SgiI4ApQARQDNylql+JSAww26OKVsB/VPU3IjIReALY6n72T1V9/njts4CphVQha4Y7Y/NGaD/CCZrmnQLdshpVUlbO8q37nS61tTnVDonu2bYx4aEhqEK5KgqgoKi7z7lSUpxf6xHvK8s4fx/0GMfhUbdnGc+6IsJCSIyNpHlMFElxUTRtGGGDGGq5gAeMiIQCPwIjgGxgIXCFqq7yKHMLkKGqN4vIBGCcqo4XkR7ATlXdJiLpwExVbVnNORYDv1XVb92A6a2qt3nbRguYWqy0CBY8B98+7szY3GsiDPkfiE4IdMsCwnNI9Nx1OSx1h0QHo/BQoXlMFImxkSTGRlW+kuIObyfFRtHIllIIWsEQMAOAh1R1lLt9H4CqPupRZqZbZp6IhAE7gAT1aJQ4w2dygWRVLfLYfwbwJdBGVdUCpp4q2OMsC7DweQhrAMkZzmzN4Q2dV0TDw+/DG0BEo2N8Xs2+0Nrb1ZRXWMKPO/MoV2dZAhBEQIAQqXgvlY8ZVe7z2O/VcSGCcORxR7wHCkvL2XWgkJ0HCtmxv5CdeUXs3F/Izjx3+0BRZXefp+jIMBJjI0mKiyIxJorEuCgSY9xtN4gSYiIJt2eIapy3AePPfyK0BLZ4bGcD/Y5VRlVLRWQ/EA/keJS5BFjiGS6uCcCbemRCXiIig3GunH6rqluqHIOI3ATcBNCmTZuT/lImyDRsCuc9Bn0mwey/OgMCCvZASTaUFDhT0pQcct5zkv+YCgn3CJwGEO6G0/FCKbyhM8otdTA0TfXLV/ZGTFQ4vdoGz7Q7LRsff+RbflEpO90QcoKo6PD7A4XM37CHnQcKKa1yVSYC8Y0iSYqLJCk2iubu1Y/n1VFSbBSNG4bbUO8ACOprUBHpAjwGjKzm4wnANR7bHwKvq2qRiPwCeAU4t+pBqvos8Cw4VzA+b7QJjGbtYdwzx/5cFUoL3cDxeFUG0MHDQVR1X7HHZxWfH8z1+NzdX15y5DmTMqDzhdD5YmjWwb/fv5aLjgwjOiGatIToY5YpL1f2FBS7Vz3Olc+OA4XsckMoe+8hlmzex56DxUcdGxEWQpumDemYFEOn5Fg6JTs/k2KjLHj8yJ8BsxVo7bHdisM34KuWyXa7yOJwusMQkVbAe8C1qrrO8yAR6QaEqeriin2qmutR5HngcR99D1MXiLhXHA1wLpL9oKzECZr83fDjZ7DqA/jqEeeV0Ak6X+S8mneq1VPgBEpIiNAsOpJm0ZGkt4w7Zrmi0jJ2HSiqvPrZ6b5fv/sgmVv28dGy7ZVl4xqEHxU6ZyTG2FxxPuLPezBhOF1Vw3CCZCFwpaqu9ChzK9DV4yb/z1T1chFpDHwDPKyq06upewpQpKp/8NiXrKrb3ffjgHtUtf/x2mj3YIzfHdgGWR/Cqhmw6TtAIb69EzSdLoTkbhY2NexAYQlrduSRtf0AWdvzWL3jAGt25FHgrmoaIpDSrJETOm74dEyOpUWcXe1UCPhNfrcR5wNP4QxTflFV/yQik4FFqjpDRKKAV4EewB5ggqquF5EHgPuAnzyqG6mqu9x61wPnq+pqj3M9ClwIlLp1/dLz8+pYwJgalbfTWdUzawZsmA1aBo3bHu5Ga9nLwiZAysuVzXsKnNDZkcfq7QfI2nGALXsOVZaJjQqjY3IsnZNj6ZgUQ8fkWM5MjKFBRP272gmKgAl2FjAmYA7mwppPnG609V87929iWzpXNZ0vgtb9gmZJ6fosr+JqpyJ0tjtXOwfdqx0RSI13rnYqQqdTcgwtGzeo01c7FjBesIAxQeHQPveezQxnNumyIohOdFb77HShM6t0aFCPx6lXysuVLXsLyNrudLOt3nGA1Tvy2JRbUFkmJiqMTkmxdHTv63RMiuHMpBgaRpza/46qSmm5Ulbu/CwtKz9iu6xMKSkvd7bLKvaXu2UPb5eVKyXudnrLWNrGNzql9ljAeMECxgSdojz4cabTjfbT586ggYbx0HGMc2WTek6tfj6nLssvKq28t7N6xwFWb89j9Y68ymd8RCAlvhGxUWGVf/gr/uhXhIXzx7/8qDDxxzOzj1ycztX9257SsRYwXrCAMUGtuMC5oln1gXOFU5wPUXFwphs2aUMhzCa6DGbl5c7S2qu2O4GzZucBCorLCAsRwkJCCA0VwkKE0JCKnyGEhx65HRYihIUeuR0aIm65w9tOmZDDx7rHhIWEEHZEnUJ4aAiJMVHENTy1f6xYwHjBAsbUGiWFzmqfqz5w7t0U7oeIGDhztNON1n6487CnMTUgGJ7kN8b4SngUnHme8yothg3fQtYHkPWRs4xBeEPoMMK5sukwss6umWNqF7uCsSsYU5uVlcKmOc4AgawP4eAuCI10rmg6ng+JXZznbixwjA9ZF5kXLGBMnVJeBlvmO91oq2ZA3rbDn0UnOdPVxLd3f3ZwpteJa2Mj1MxJs4DxggWMqbPKyyHnR+eVu9Z55fwEuT/Bob2Hy4VGQJPUo8Mnvj008tOUOqbWs3swxtRnISHQvKPzqupgrhM0OT8dGT4/zjxyws4GTdwrHc/waQ9N29noNeMVCxhj6ptG8c6rTZWp+spKYd+mI692ctfB2i8hc9rhchICjdscGT4VARSTbNPdmEoWMMYYR2gYxKc5rzNGHflZ4YGju9py1zoTeJYcfoKdiGi3jirhE98eIo89Fb+pmyxgjDEnFhULLXs6L0/l5c5ggorutorwyV4AK97liEXeYlo44VM5yKCDs924LYTUvwkj6wMLGGPMqQsJgbhWzitt6JGflRyCPeuPvtez4l3nQdEKoRHOfR3Prrb49k4I1daBBqXFkLfdeR3Ydvhn/k6IbeFM+dNmQJ1/ONYCxhjjH+ENnOdwErscuV8VCnKP7GrLWeuMeKt2oEH7w8Oq4z0GGoRH1ez3qWj7ob1uYGx3rt6q+1mQc/SxYVHOJKYHtsF3f3eCtVVfaHeOEzgte9a5eeZsmLINUzYmeHgONKjscnPf5233KCjuQIP21Qw0aHFqSx2UFkP+jmMEh8eVSGnh0cc2SnAGOMS2qPIz2WlPbDJENXYGQBQfhM3zYP03sOEb2L4MUOf+VduBTti0OweadwnaJRvsORgvWMAYU4sU5blhs+7oq5+Sg4fLhTd0Bxq0P/JeT1iD6gOj4ufB3UefMyzq2IFR8TM6CcIiTv17FeyBjbMPB07uWmd/w2aQOuhw4DRJDZoRehYwXrCAMaYOUHUCouoVT85PztWQlld/XMNm1QdG5c9kp4uupv+o78925pqrCJyKK7e4NtBuMKQOgdTBEJNYs+3yYAHjBQsYY+q40iLYu9EJm7Liw1ciMUm142FRVaftG75xVj7dOPvwAImETofv36Sc5SzlUEOCImBEZDTwdyAUeF5Vp1T5PBKYCvQCcoHxqrpRREYAU4AIoBi4S1W/co/5GkgGKhbLHqmqu45V1/HaZwFjjKlVystg+1I3cL6Bzd9D6SGQUGjR43DgtO7n10EQAQ8YEQkFfgRGANnAQuAKVV3lUeYWIENVbxaRCcA4VR0vIj2Anaq6TUTSgZmq2tI95mvgTlVdVOV81dZ1vDZawBhjarXSItiy4HDgbF0MWubcO2rdzw2cIdCiu0+fNQqGgBkAPKSqo9zt+wBU9VGPMjPdMvNEJAzYASSoR6NERHCuSJJVteg4AXPCuqqygDHG1CmFB2DT3MOBs2ulsz8yDlLOdgNnMCR0PK17S8Ew2WVLYIvHdjbQ71hlVLVURPYD8YDnIPJLgCWqWuSx7yURKQPeBR5xQ8SbuhCRm4CbANq0aXNaX9AYY4JKVKyzyumZo53t/N1O2FQEzpqPnf3RiTDqz9D1Ur82J6gftBSRLsBjwEiP3Vep6lYRicEJmGtw7r14RVWfBZ4F5wrGh801xpjgEp3ghEhFkOzdeHh0WkyS30/vz4DZCrT22G7l7quuTLbbrRWH0x2GiLQC3gOuVdV1FQeo6lb3Z56IvAb0xQmYY9ZljDEGaJICvVKg13U1cjp/Pia6EOggIqkiEgFMAGZUKTMDqPimlwJfqaqKSGPgY+BeVf2uorCIhIlIM/d9ODAWWHG8uvzwvYwxxnjBb1cw7n2Q24CZOMOUX1TVlSIyGVikqjOAF4BXRWQtsAcnhABuA9oDD4rIg+6+kcBBYKYbLqHAF8Bz7ufHqssYY0wA2IOWNorMGGNOirejyIJzJjVjjDG1ngWMMcYYv7CAMcYY4xcWMMYYY/zCAsYYY4xf1OtRZCKyG9h0ioc3o8o0NPWc/T6OZL+Pw+x3caS68Ptoq6oJJypUrwPmdIjIIm+G6dUX9vs4kv0+DrPfxZHq0+/DusiMMcb4hQWMMcYYv7CAOXXPBroBQcZ+H0ey38dh9rs4Ur35fdg9GGOMMX5hVzDGGGP8wgLGGGOMX1jAnAIRGS0ia0RkrYjcG+j2BIqItBaRWSKySkRWisivA92mYCAioSLyg4h8FOi2BJqINBaRd0RktYhkiciAQLcpUETkt+7/T1aIyOsiEhXoNvmbBcxJEpFQ4GngPKAzcIWIdA5sqwKmFPidqnYG+gO31uPfhadfA1mBbkSQ+Dvwmap2BLpRT38vItIS+BXQW1XTcdazqvNrVlnAnLy+wFpVXa+qxcAbwEUBblNAqOp2VV3ivs/D+ePRMrCtCix3qe8xwPOBbkugiUgcMBhnMUBUtVhV9wW2VQEVBjRwl3RvCGwLcHv8zgLm5LUEtnhsZ1PP/6gCiEgK0AOYH9iWBNxTwN1AeaAbEgRSgd3AS26X4fMi0ijQjQoEVd0K/AXYDGwH9qvqfwPbKv+zgDGnTUSigXeB36jqgUC3J1BEZCywS1UXB7otQSIM6Ak8o6o9cJY8r5f3LEWkCU5PRyrQAmgkIlcHtlX+ZwFz8rYCrT22W7n76iURCccJl2mqOj3Q7Qmws4ALRWQjTtfpuSLyn8A2KaCygWxVrbiqfQcncOqj4cAGVd2tqiXAdGBggNvkdxYwJ28h0EFEUkUkAudG3YwAtykgRERw+tezVPVvgW5PoKnqfaraSlVTcP67+EpV6/y/Uo9FVXcAW0TkTHfXMGBVAJsUSJuB/iLS0P3/zTDqwYCHsEA3oLZR1VIRuQ2YiTMS5EVVXRngZgXKWcA1wHIRyXT3/Y+qfhLANpngcjswzf3H2Hrg+gC3JyBUdb6IvAMswRl9+QP1YMoYmyrGGGOMX1gXmTHGGL+wgDHGGOMXFjDGGGP8wgLGGGOMX1jAGGOM8QsLGGNqKREZYjM2m2BmAWOMMcYvLGCM8TMRuVpEFohIpoj8210vJl9EnnTXB/lSRBLcst1F5HsRWSYi77lzWCEi7UXkCxFZKiJLRCTNrT7aY72Vae5T4sYEBQsYY/xIRDoB44GzVLU7UAZcBTQCFqlqF+Ab4A/uIVOBe1Q1A1jusX8a8LSqdsOZw2q7u78H8BuctYna4cyuYExQsKlijPGvYUAvYKF7cdEA2IUznf+bbpn/ANPd9VMaq+o37v5XgLdFJAZoqarvAahqIYBb3wJVzXa3M4EUYI7/v5YxJ2YBY4x/CfCKqt53xE6R31cpd6pzNhV5vC/D/j9tgoh1kRnjX18Cl4pIcwARaSoibXH+v3epW+ZKYI6q7gf2isggd/81wDfuaqHZInKxW0ekiDSs0W9hzCmwf+0Y40equkr+v707tkEghqEA+k3NPGxCiRiAFaiYAlZhJOrrKEJxKaiRzDXvtZGipPqyIzlV1yTPqtoleSe5ZP186zDXXlnfaZLknOQ+A+R7+vApyaOqbnOP4x+vAT8xTRk2UFXLGGO/9TmgkxYZAC1UMAC0UMEA0ELAANBCwADQQsAA0ELAANDiA33fo/cAAAAESURBVJCv6UKSKXTnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_count = 10\n",
    "\n",
    "model = create_mnist_model(loss=CategoricalCrossentropy(), optimizer=SGD(lr=0.01, momentum=0))\n",
    "model.fit(X_train[0:,], y_train[0:,], 10, epoch_count, X_val=X_val[0:,], Y_val=y_val[0:,])\n",
    "\n",
    "print(\"accuracy model without momentum\", model.evaluate(X_test, y_test, 10, \"accuracy\"))\n",
    "\n",
    "model_momentum = create_mnist_model(loss=CategoricalCrossentropy(), optimizer=SGD(lr=0.01, momentum=1))\n",
    "model_momentum.fit(X_train[0:,], y_train[0:,], 10, epoch_count, X_val=X_val[0:,], Y_val=y_val[0:,])\n",
    "\n",
    "print(\"accuracy model with momentum\", model_momentum.evaluate(X_test, y_test, 10, \"accuracy\"))\n",
    "\n",
    "plt.subplot();\n",
    "plt.title(\"train\")\n",
    "plt.xlabel(\"epoch\");\n",
    "plt.ylabel(\"loss\");\n",
    "plt.plot(range(epoch_count), model_momentum.loss_train_history, label=\"loss_train_with_momuntum\");\n",
    "plt.plot(range(epoch_count), model.loss_train_history, label=\"loss_train_without_momuntum\");\n",
    "plt.legend()\n",
    "plt.show();\n",
    "\n",
    "plt.subplot();\n",
    "plt.title(\"val\")\n",
    "plt.xlabel(\"epoch\");\n",
    "plt.ylabel(\"loss\");\n",
    "plt.plot(range(epoch_count), model.loss_val_history, label=\"loss_val_without_momuntum\");\n",
    "plt.plot(range(epoch_count), model_momentum.loss_val_history, label=\"loss_val_with_momuntum\");\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Графики двух моделей(модель с моментом имупльса и без) показывают, что модель с моментом дает лучший результат в данной задаче.\n",
    "Так как график модели с моментом импульса лежит срого ниже графика модели без момента.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
